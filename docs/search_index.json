[["index.html", "Integración del Paquete QualityTools con Tidyverse Capítulo 1 Preámbulo", " Integración del Paquete QualityTools con Tidyverse Miguel Flores Andrea Barahona Fabián Encarnación Dario Quishpe 2024-04-25 Capítulo 1 Preámbulo En este libro, se pretende combinar la información necesaria para entender los paquetes R6, Tidyquant y QualityTools, con la finalidad de tener toda la infomación necesaria en un solo documento. "],["poo-programación-orientada-a-objetos.html", "Capítulo 2 (POO) Programación Orientada a Objetos 2.1 Introducción 2.2 Sistemas de programación orientada a objetos 2.3 Tipos de objetos", " Capítulo 2 (POO) Programación Orientada a Objetos 2.1 Introducción En primer lugar debemos tener en mente que la POO en R presenta ciertos desafíos en comparación con otros lenguajes esto debido a : La presencia de más de un sistema de OOP para elegir. Dentro de los más importantes tenemos : S3, R6 y S4. Donde S3 y S4 vienen en R base y R6 en el paquete con la misma denominación Existe discrepancia sobre la importancia de los sistemas POO mencionado. La sintaxis utilizada para la implementación de la POO en R en comparación con otros lenguajes populares es diferente. Aunque la programación funcional es más utilizada en R que la POO, es importante comprender estos sistemas por las siguientes razones : S3 permite que las funciones devuelvan resultados con una visualización amigable y una estructura interna agradable para el programador. S3 se utiliza en todo R base, por lo que es importante dominarlo si se desea modificar las funciones de R base para trabajar con nuevos tipos de entrada. R6 proporciona una forma de escapar de la semántica copy-on-modify de R. Esto es especialmente importante si se desea modelar objetos que existen independientemente de R. Hoy en día, una necesidad común de R6 es modelar datos que provienen de una API web, y donde los cambios provienen de dentro o fuera de R. S4 es un sistema riguroso que obliga a pensar detenidamente en el diseño de los programas. Es adecuado para la construcción de grandes sistemas que evolucionan con el tiempo y recibirán contribuciones de muchos programadores. 2.2 Sistemas de programación orientada a objetos La principal razón para utilizar la POO es el polimorfismo. El polimorfismo significa que un programador puede considerar la interfaz de una función separadamente de su implementación, lo cual hace posible usar la misma forma de función para diferentes tipos de entrada. Esto está estrechamente relacionado con la idea de encapsulación: el usuario no necesita preocuparse por los detalles de un objeto porque están encapsulados tras una interfaz estándar. Para ejemplificar esta idea, el polimorfismo es lo que permite a summary() producir diferentes salidas para diferentes entradas: #Utilizamos el dataframe diamonds diamonds &lt;- ggplot2::diamonds #carat: variable cuantitativa summary(diamonds$carat) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.2000 0.4000 0.7000 0.7979 1.0400 5.0100 #cut: Variable cualitativa summary(diamonds$cut) ## Fair Good Very Good Premium Ideal ## 1610 4906 12082 13791 21551 Esto no implica que summary() contenga una serie if-else para cada caso. Los sistemas de POO llaman clase a lo que define que es un objeto y los métodos describen lo que ese objeto puede hacer. La clase define los campos, las características que posee cada instancia de esa clase (variables ,propiedades ,métodos). Las clases se organizan en una jerarquía de forma que si un método no existe para una clase, se utiliza el método de su padre, y se dice que el hijo hereda el comportamiento. Por ejemplo, en R, un factor ordenado hereda de un factor regular, y un modelo lineal generalizado hereda de un modelo lineal. El proceso de encontrar el método correcto dada una clase se denomina despacho del método. 2.2.1 Paradigmas Existen dos paradigmas principales de POO : encapsulado y funcional: En la POO encapsulada, los métodos pertenecen a objetos o clases, y las llamadas a métodos suelen tener el aspecto de object.method(arg1, arg2). Se denomina encapsulada porque el objeto encapsula tanto las variables (con campos) como el comportamiento (con métodos), y es el paradigma que se encuentra en los lenguajes más populares (Python,Java,C,C++). En la POO funcional, los métodos pertenecen a funciones genéricas, y las llamadas a métodos parecen llamadas a funciones ordinarias: generic(object, arg2, arg3). Esto se llama funcional porque desde fuera parece una llamada a una función normal, e internamente los componentes también son funciones. 2.2.2 Especificaciones de los principales sistemas POO en R Sistemas POO del R base: S3, S4 y RC : S3 es el primer sistema POO de R, el cual es una implementación informal de POO funcional y se basa en convenciones comunes en lugar de garantías férreas. Esto hace que sea fácil empezar a trabajar con él, proporcionando una forma de óptima de resolver muchos problemas sencillos. S4 es una reescritura formal y rigurosa de S3, esta requiere más trabajo inicial que S3, pero a cambio proporciona más garantías y una mayor encapsulación. S4 se implementa en el paquete de métodos base, que siempre se instala con R. Dentro de S4 tenemos RC la cual implementa POO encapsulada. Los objetos RC son un tipo especial de objetos S4 que también son mutables, es decir, en lugar de utilizar la semántica habitual de R de copy-on-modify, pueden modificarse en ese mismo lugar específico. Esto los hace más difíciles de razonar, pero les permite solucionar problemas que son difíciles de resolver en el estilo funcional POO de S3 y S4. El sistema POO proporcionado por paquete CRAN de nuestro interes es: R6 implementa POO encapsulada como RC, pero resuelve algunos problemas importantes.Mas adelante se aprenderá a detalle sobre el uso R6 . 2.3 Tipos de objetos Para tratar el tema de objetos y POO en R, en primer lugar se tiene que aclarar la confusión entre los usos de la palabra “objeto”. Por lo general se piensa que “Todo lo que existe en R es un objeto”, sin embargo, aunque todo es un objeto, no todo está orientado a objetos. Esta confusión surge porque los objetos de R base proceden de S, y se desarrollaron antes de que nadie pensara que S podría necesitar un sistema POO. Los términos que se usan para diferenciar los dos tipos de objeto son: objetos base y objetos OO para distinguirlos. 2.3.1 Objetos Base vs Objetos OO Para diferenciar entre un objeto base y uno OO, se utiliza is.object() o sloop::otype() #EJEMPLO 1 # UN OBJETO BASE: is.object(1:10) ## [1] FALSE sloop::otype(1:10) ## [1] &quot;base&quot; # Utilizamos el dataframe mtcars # UN OBJETO OO is.object(mtcars) ## [1] TRUE sloop::otype(mtcars) ## [1] &quot;S3&quot; Para diferenciarlos también se puede tomar en cuenta que solo los objetos OO tienen el atributo “class” #Objeto base attr(1:10, &quot;class&quot;) ## NULL #Objeto OO attr(mtcars, &quot;class&quot;) ## [1] &quot;data.frame&quot; por otro lado cada objeto tiene un base type: #Objeto Base typeof(1:10) ## [1] &quot;integer&quot; #Objeto OO typeof(mtcars) ## [1] &quot;list&quot; En total, hay 25 tipos de base type diferentes. Estos tipos son más importantes en código C, por lo que a menudo se verán llamados por sus nombres de tipo C (estos se encuentran en paréntesis). Los presentamos a continuación Para vectores tenemos los tipos : Tipo Descripción NULL (NILSXP) Tipo nulo logical (LGLSXP) Tipo lógico integer (INTSXP) Tipo entero double (REALSXP) Tipo decimal de precisión doble complex (CPLXSXP) Tipo complejo character (STRSXP) Tipo caracter list (VECSXP) Tipo lista raw (RAWSXP) Tipo de datos binarios #EJEMPLOS #NULL typeof(NULL) ## [1] &quot;NULL&quot; #integer typeof(1L) ## [1] &quot;integer&quot; #COMPLEX typeof(1i) ## [1] &quot;complex&quot; Para funciones : Tipo Descripción closure (CLOSXP) Funciones regulares de R special (SPECIALSXP) Funciones internas de R builtin (BUILTINSXP) Funciones primitivas de R #Ejemplos typeof(mean) #closure ## [1] &quot;closure&quot; typeof(`[`) #special ## [1] &quot;special&quot; typeof(sum) #builtin ## [1] &quot;builtin&quot; Para Entornos : environment (ENVSXP). #Ejemplos typeof(globalenv()) ## [1] &quot;environment&quot; Para Componentes de Lenguaje : incluyen Tipo Información extra symbol (SYMSXP) Conocido como:name language (LANGSXP) Conodido como: calls pairlist (LISTSXP) Utilizado para los argumentos de funciones #Ejemplos # &quot;symbol&quot; typeof(quote(a)) ## [1] &quot;symbol&quot; #&quot;language&quot; typeof(quote(a + 1)) ## [1] &quot;language&quot; #&quot;pairlist&quot; typeof(formals(mean)) ## [1] &quot;pairlist&quot; Los tipos restantes son esotéricos y raramente vistos en R. Son importantes principalmente para el código C: externalptr (EXTPTRSXP), weakref (WEAKREFSXP), bytecode (BCODESXP), promise (PROMSXP), … (DOTSXP), and any (ANYSXP). Ahora hay que tener cuidado al momento de referirnos sobre los tipos númericos : numeric type , pues el tipo numeric en R suele utilizarce para referirse a 3 cosas ligeramentes distintas : En algunos lugares numeric se utiliza como alias del tipo double. Por ejemplo as.numeric() es idéntico a as.double(), y numeric() es idéntico a double(). (R también utiliza ocasionalmente real en lugar de double; NA_real_ es el único lugar donde es probable encontrar esto en la práctica). En los sistemas S3 y S4, numeric se utiliza como una abreviatura para el tipo integer o double, y se utiliza cuando se seleccionan métodos: #EJEMPLOS #&quot;double&quot; &quot;numeric&quot; sloop::s3_class(1) ## [1] &quot;double&quot; &quot;numeric&quot; #&quot;integer&quot; &quot;numeric&quot; sloop::s3_class(1L) ## [1] &quot;integer&quot; &quot;numeric&quot; is.numeric() comprueba si los objetos se comportan como números . Por ejemplo, los factores tienen tipo “entero” pero no se comportan como números (es decir, no tiene sentido tomar la media del factor). #Factor es tipo entero typeof(factor(&quot;x&quot;)) ## [1] &quot;integer&quot; # Pero NO SE COMPORTAN COMO ENTERO is.numeric(factor(&quot;x&quot;)) ## [1] FALSE "],["r6.html", "Capítulo 3 R6 3.1 Clases y métodos 3.2 Controles de Acceso 3.3 Semántica de referencia 3.4 ¿Por qué R6? 3.5 Ejercicios prácticos", " Capítulo 3 R6 El sistema POO R6 se lo puede empezar analizando mediante sus dos propiedades especiales : -Utiliza el paradigma de POO encapsulada, lo que significa que los métodos pertenecen a los objetos, no a los genéricos, y se se los puede llamar mediante object$method(). -Los objetos R6 son mutables, lo que significa que se modifican en el lugar, y por lo tanto tienen semántica de referencia. Si se tiene conocimientos de POO en otros lenguajes es probable que R6 resulte muy natural y sea una buena alternativa a S3. Los temas a tratar en referencia a R6 son los siguiente : Clases y métodos : R6::R6Class() la única función que necesitas conocer para crear clases R6. Aprenderás sobre el método constructor, $new(), que te permite crear objetos R6, así como otros métodos importantes como $initialize() y $print(). Controles de acceso: mecanismos de acceso de R6 , campos privados y activos. Juntos, permiten ocultar datos al usuario, o exponer datos privados para su lectura pero no para su escritura. Semántica de referencia : explora las consecuencias de la semántica de referencia de R6. Se aprende el uso de finalizadores para limpiar automáticamente cualquier operación realizada en el inicializador, y un problema común si usas un objeto R6 como campo en otro objeto R6. Por qué R6 en lugar del sistema RC base? Requisito : #install.packages(&quot;R6&quot;) library(R6) 3.1 Clases y métodos Para crear las clases y sus métodos se utiliza: R6::R6Class() Por ejemplo: SumaAcum &lt;- R6Class(&quot;SumaAcum&quot;,list( suma = 0, sumar = function(x=1){ self$suma&lt;-self$suma+x invisible(self) } )) En el ejemplo se muestra los argumentos que deben ir en la función R6Class(): El primer argumento es el nombre de la clase, el cual no es necesario, pero evita errores. El segundo argumento son los métodos (funciones) y campos (variables) públicos del objeto. Los métodos pueden acceder a los métodos y campos del mismo objeto mediante self Para crear un nuevo objeto se utiliza el método $new(): x &lt;- SumaAcum$new() x ## &lt;SumaAcum&gt; ## Public: ## clone: function (deep = FALSE) ## suma: 0 ## sumar: function (x = 1) Además, se accede a los campos y se llama a los métodos mediante $: x$sumar(2) x$suma ## [1] 2 x$sumar(4) x$suma ## [1] 6 x$sumar() x$suma ## [1] 7 Vemos también que se utiliza self$ para acceder a los miembros y métodos públicos de la clase (se puede usar private$ o super$ para miembros privados o que heredan que se verá más adelante) 3.1.1 Encadenamiento de métodos Debido a como se crean los métodos podemos realizar un encadenamiento, por ejemplo: y &lt;- SumaAcum$new() y$sumar(5)$sumar(10) y$suma ## [1] 15 Este encadenamiento está relacionados con los pipe y se revisará más adelante los pros y contras de esto. 3.1.2 Métodos importantes El método $initialize() modifica el comportamiento de $new(), por ejemplo: Persona &lt;- R6Class(&quot;Persona&quot;,list( nombre = NULL, edad = NA, initialize = function(nombre, edad= NA){ stopifnot(is.character(nombre), length(nombre)==1) stopifnot(is.numeric(edad), length(edad)==1) self$nombre &lt;- nombre self$edad &lt;- edad } )) De esta forma se asegura que el nombre sea un solo string y que la edad sea un solo número. Creemos por ejemplo: Andrea &lt;- Persona$new(&quot;Andrea&quot;, &#39;veintidos&#39;) ## Error in initialize(...): is.numeric(edad) is not TRUE Por lo tanto no se crea, debido a que 'veintidos' no es un número, y si se creará cuando lo creemos de esta forma: Andrea &lt;- Persona$new(&quot;Andrea&quot;, 22) En caso de tener requisitos más complejos se puede utilizar $validate() El método $print() permite modificar el comportamiento de la impresión por defecto, por ejemplo: Persona &lt;- R6Class(&quot;Persona&quot;, list( nombre = NULL, edad = NA, initialize = function(nombre, edad = NA) { self$nombre &lt;- nombre self$edad &lt;- edad }, print = function(...) { cat(&quot;Persona: \\n&quot;) cat(&quot;Nombre: &quot;, self$nombre, &quot;\\n&quot;, sep = &quot;&quot;) cat(&quot;Edad: &quot;, self$edad, &quot;\\n&quot;, sep = &quot;&quot;) invisible(self) } )) Andrea2 &lt;- Persona$new(&quot;Andrea&quot;) Andrea2 ## Persona: ## Nombre: Andrea ## Edad: NA Ahora vemos que el objeto creado anteriormente no tiene relación con este nuevo, pues cada método está vinculado a un objeto individual. Vemos que: Andrea ## &lt;Persona&gt; ## Public: ## clone: function (deep = FALSE) ## edad: 22 ## initialize: function (nombre, edad = NA) ## nombre: Andrea Andrea2 ## Persona: ## Nombre: Andrea ## Edad: NA No imprimen lo mismo. 3.1.3 Agregar métodos después de la creación Para evitar crear nuevas clases, se puede modificar los campos o métodos de una ya existente. Se utiliza $set() para agregar nuevos elementos. Por ejemplo: SumAcum &lt;- R6Class(&quot;SumAcum&quot;) SumAcum$set(&quot;public&quot;, &quot;suma&quot;, 0) SumAcum$set(&quot;public&quot;, &quot;sumar&quot;, function(x=1){ self$suma &lt;- self$suma + x invisible(self) }) Para agregarlos debemos proporcionar: visibilidad (public, entre otros), nombre y lo que se va a agregrar. De esta forma se crea este objeto igual al que se creó en la primera sección. Además, si se agregan nuevo campos o métodos solo estarán disponibles para los nuevos objetos creados a partir de esto. Para evitar aumentar métodos o campos se puede bloquear la clase mediante lock_class=TRUE, de la siguiente forma: SumaAcum &lt;- R6Class(&quot;SumaAcum&quot;,list( suma = 0, sumar = function(x=1){ self$suma&lt;-self$suma+x invisible(self) }), lock_class = TRUE ) De esta forma si intentamos utilizar $set() se tendrá un error: SumaAcum$set(&#39;public&#39;,&#39;y&#39;,0) ## Error in SumaAcum$set(&quot;public&quot;, &quot;y&quot;, 0): Can&#39;t modify a locked R6 class. Se puede también bloquear o desbloquear la clase mediante $lock() y $unlock() respectivamente. ###Herencia Se puede heredar los comportamientos de una clase existente a otra utilizando inherit, para ello veamos el ejemplo: SumAcumMsg &lt;- R6Class(&quot;SumAcumMsg&quot;, inherit = SumAcum, public = list( sumar = function(x=1){ cat(&quot;Sumando &quot;, x, &quot;\\n&quot;, sep=&quot;&quot; ) super$sumar(x=x) } ) ) Al agregar $sumar() se cambia la implementación de la clase que hereda (Super clase) y se modifica con la que se implementa en el código. Vemos que se puede acceder al método de la Super clase mediante super$, y cualquier método que no se modifique utilizará los métodos de la Super Clase. x2 &lt;- SumAcumMsg$new() x2$sumar(5)$sumar(3)$suma ## Sumando 5 ## Sumando 3 ## [1] 8 ###Introspección Para determinar la clase y todas las que hereda podemos utilizar class(): class(x2) ## [1] &quot;SumAcumMsg&quot; &quot;SumAcum&quot; &quot;R6&quot; Podemos ver que métodos y campos contiene utilizando name(): names(Andrea2) ## [1] &quot;.__enclos_env__&quot; &quot;edad&quot; &quot;nombre&quot; &quot;clone&quot; ## [5] &quot;print&quot; &quot;initialize&quot; 3.2 Controles de Acceso R6Class() tiene otros 2 argumentos que funcionan similar a public: private permite crear campos y métodos que solo están disponibles dentro de la clase y no fuera de ella. active permite utilizar funciones de acceso para definir campos dinámicos o activos. 3.2.1 Privacidad Con R6 es posible definir campos y metodos privados, es decir, que solo están disponibles dentro de la clase. Otros aspectos importantes de conocer son: El argumento private en R6Class se declara de la misma forma en la que se hace el argumento public, es decir, asigmar una lista de métodos (funciones) y campos (variables). Los campos y métodos definidos en private estarán disponible dentro de los métodos usando private$ en lugar de self$. Para poner esto en práctica, escribamos los campos $edad y $nombre como argumentos privados de la clase Persona. Una vez definidos de esta forma, solo podremos establecer $edad y $nombre durante la creación del objeto, y no tendremos acceso a estos valores fuera de la clase. Persona &lt;- R6Class(&quot;Persona&quot;, public = list( initialize = function(nombre, edad = NA) { private$nombre &lt;- nombre private$edad &lt;- edad }, print = function(...) { cat(&quot;Persona: \\n&quot;) cat(&quot; Nombre: &quot;, private$nombre, &quot;\\n&quot;, sep = &quot;&quot;) cat(&quot; Edad: &quot;, private$edad, &quot;\\n&quot;, sep = &quot;&quot;) } ), private = list( edad = NA, nombre = NULL ) ) Andrea3 &lt;- Persona$new(&quot;Andrea&quot;) Andrea3 ## Persona: ## Nombre: Andrea ## Edad: NA Andrea3$nombre ## NULL Esta distinción entre campos públicos y privados es importante cuando se crea redes complejas de clases, ya que será fundamental tener claro a los campos que otros podrán acceder y cuales no. Todo lo que sea privado se puede refactorizar más fácilmente porque sabes que los demás no dependen de estos campos. Los métodos privados tienden a ser menos importantes en R en comparación con otros lenguajes de programación porque las jerarquías de objetos en R tienden a ser más simples. 3.2.2 Campos Activos Los campos activos permiten definir componentes que funcionan como campos para los usuarios, pero están definidos como funciones, es decir, como métodos. Los campos activos están implementados usando enlaces activos, que son funciones que toman un único argumento (value), si el argumento es missing(), significa que el valor se está recuperando, o de lo contrario se está modificando. Por ejemplo, creemos un campo activo llamado random que nos devuelva un valor diferente cada que accedemos a el: Ran &lt;- R6::R6Class(&quot;Ran&quot;, active = list( random = function(value) { if (missing(value)) { runif(1) } else { stop(&quot;Can&#39;t set `$random`&quot;, call. = FALSE) } } )) x &lt;- Ran$new() x$random ## [1] 0.3432418 x$random ## [1] 0.4827372 x$random ## [1] 0.4652731 Los campos activos son usandos particularmente junto con el argumento de campos privamos, ya que esto hace posible implementar componentes similares a los campos pero con controles adicionales. Por ejemplo, podemos usar esto para crear un campo solo de lectura para edad, y para asegurarnos que nombre sea un vector de un solo caracter. Persona &lt;- R6Class(&quot;Person&quot;, private = list( .edad = NA, .nombre = NULL ), active = list( edad = function(value) { if (missing(value)) { private$.edad } else { stop(&quot;`$edad` solo se puede leeer&quot;, call. = FALSE) } }, name = function(value) { if (missing(value)) { private$.nombre } else { stopifnot(is.character(value), length(value) == 1) private$.nombre &lt;- value self } } ), public = list( initialize = function(nombre, edad = NA) { private$.nombre &lt;- nombre private$.edad &lt;- edad } ) ) Andrea4 &lt;- Persona$new(&quot;Andrea&quot;, edad = 22) Andrea4$nombre ## NULL Andrea4$nombre &lt;- 10 ## Error in Andrea4$nombre &lt;- 10: no se pueden adicionar vínculos a un ambiente bloqueado Andrea4$edad &lt;- 20 ## Error: `$edad` solo se puede leeer 3.3 Semántica de referencia Una de las grandes diferencias entre R6 y la mayoría de los demás objetos es que tienen una semántica de referencia. La principal consecuencia de la semántica de referencia es que los objetos no se copian cuando se modifican: y1 &lt;- SumaAcum$new() y2 &lt;- y1 y1$sumar(10) c(y1 = y1$suma, y2 = y2$suma) ## y1 y2 ## 10 10 En cambio, si queremos copiar, necesitamos expecificarlo con el método $clone(): y1 &lt;- SumaAcum$new() y2 &lt;- y1$clone() y1$sumar(10) c(y1 = y1$suma, y2 = y2$suma) ## y1 y2 ## 10 0 ($clone() no clona recursivamente objetos R6 anidados. Si quieres eso, necesitarás usar $clone(deep = TRUE).) Hay otras tres consecuencias menos intuitivas: Es más difícil razonar sobre el código que utiliza objetos R6 porque es necesario comprender más contexto. Tiene sentido pensar en cuándo se elimina un objeto R6 y puede escribir $finalize() para complementar $initialize(). Si uno de los campos es un objeto R6, debe crearlo dentro de $initialize(), no de R6Class(). Estas están descritas con mayor detalle a continuación. 3.3.1 Razonamientos Generalmente, las semanticas de referencias hacen el código más difícil de entender. Tomemos el siguiente ejemplo sencillo: x &lt;- list(a = 1) y &lt;- list(b = 2) z &lt;- f(x, y) Para la gran mayoría de funciones, sabes que la línea final solo modifica z. Ahora, tomemos un ejemplo similar que utiliza una clase de referencia de Lista imaginaria: x &lt;- Lista$new(a = 1) y &lt;- Lista$new(b = 2) z &lt;- f(x, y) Es mucho más difícil de entender la línea final: si f() llama a métodos de x o y, podría modificarlos al igual que z. Este es el mayor inconveniente potencial de R6 y se debe tener cuidado de evitarlo escribiendo funciones que devuelvan un valor o modifiquen sus entradas de R6, pero no ambas. 3.3.2 Finalización La semántica de referencia, permite pensar en el momento en que un objeto R6 es finalizado o eliminado. Esto es diferente a la mayoría de los objetos en R, donde la semántica de copia al modificar significa que puede haber muchas versiones transitorias de un objeto, lo que no permite pensar en cuándo se elimina un objeto de forma lógica. Por ejemplo, en el caso de objetos de tipo factor en R, cuando se modifican los niveles de un factor, se crea un nuevo objeto factor y el objeto original se deja para que lo recolecte el recolector de basura. x &lt;- factor(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) levels(x) &lt;- c(&quot;c&quot;, &quot;b&quot;, &quot;a&quot;) Debido a que los objetos R6 no se copian al modificarlos, solo se eliminan una vez, tiene sentido pensar en el método $finalize() como un complemento al método $initialize(). Los finalizadores generalmente tienen un papel similar a on.exit(), limpiando cualquier recurso creado por el inicializador. ArchivoTemporal &lt;- R6Class(&quot;ArchivoTemporal&quot;, list( ruta = NULL, initialize = function() { self$ruta &lt;- tempfile() }, finalize = function() { message(&quot;Cleaning up &quot;, self$ruta) unlink(self$ruta) } )) El ejemplo proporcionado muestra una clase llamada ArchivoTemporal, que encapsula un archivo temporal y se encarga de eliminarlo automáticamente cuando se finaliza la instancia de la clase. El método finalize será ejecutado cuando el objeto sea eliminado (o más precisamente, por la primera recolección de basura después de que el objeto haya sido desligado de todos los nombres) o cuando R se cierre. Esto significa que el finalizador puede ser llamado efectivamente en cualquier parte de tu código en R, lo que hace casi imposible razonar sobre el código del finalizador que toca estructuras de datos compartidas. Se recomienda evitar estos posibles problemas utilizando el finalizador solo para limpiar recursos privados asignados por el inicializador. Finalmente, veamos cómo se utiliza esta clase ArchivoTemporal creando una instancia, luego eliminando explícitamente la instancia con rm(), lo que provoca que el finalizador se ejecute para limpiar el archivo temporal. at &lt;- ArchivoTemporal$new() rm(at) En resumen, los objetos R6 permiten definir métodos initialize y finalize, que se ejecutan al crear y eliminar instancias de la clase respectivamente, permitiendo una gestión más controlada de los recursos y la limpieza de la memoria. 3.3.3 Campos en R6 Una última consecuencia que puede surgir al utilizar semántica de referencia en R6, es particularmente cuando se usa una instancia de una clase R6 como valor predeterminado de un campo. La semántica de referencia significa que cuando asignas un objeto a otro, no se crea una copia independiente, sino que ambos hacen referencia al mismo objeto en la memoria. Por ejemplo, creemos una clase llamada DatabaseTemporal que tiene un campo archivo, que es una instancia de la clase ArchivoTemporal. Por ejemplo, dado el siguiente código, queremos crear una base de datos temporal cada vez que llamamos a DatabaseTemporal$new(), pero el código actual siempre usa la misma ruta. DatabaseTemporal &lt;- R6Class(&quot;DatabaseTemporal&quot;, list( con = NULL, file = ArchivoTemporal$new(), initialize = function() { self$con &lt;- DBI::dbConnect(RSQLite::SQLite(), ruta = file$ruta) }, finalize = function() { DBI::dbDisconnect(self$con) } )) db_a &lt;- DatabaseTemporal$new() db_b &lt;- DatabaseTemporal$new() db_a$file$ruta == db_b$file$ruta ## [1] TRUE (Si está familiarizado con Python, esto es muy similar al problema del “argumento predeterminado mutable”). El problema es que, cuando se usa una instancia de clase como valor predeterminado para un campo, esa instancia se comparte entre todas las instancias de la clase. Por lo tanto, cada instancia de DatabaseTemporal está haciendo referencia al mismo objeto ArchivoTemporal, en lugar de tener su propia instancia única. Para solucionar este problema, se debe crear una nueva instancia de ArchivoTemporal dentro del método initialize(), de modo que cada instancia de DatabaseTemporal tenga su propia instancia única de ArchivoTemporal. DatabaseTemporal &lt;- R6Class(&quot;DatabaseTemporal&quot;, list( con = NULL, archivo = NULL, initialize = function() { self$archivo &lt;- ArchivoTemporal$new() self$con &lt;- DBI::dbConnect(RSQLite::SQLite(), ruta = file$ruta) }, finalize = function() { DBI::dbDisconnect(self$con) } )) db_a &lt;- DatabaseTemporal$new() db_b &lt;- DatabaseTemporal$new() db_a$archivo$ruta == db_b$archivo$ruta ## [1] FALSE Ahora, cada instancia de DatabaseTemporal tiene su propia instancia única de ArchivoTemporal, y por lo tanto, sus caminos de archivo son diferentes, como se espera. Esto garantiza que cada instancia de DatabaseTemporal tenga sus propios recursos independientes. 3.4 ¿Por qué R6? Este texto explica por qué el autor prefiere utilizar R6 en lugar de Reference Classes (RC), una sistema de programación orientada a objetos (OO) incorporado en R, debido a las siguientes razones: Simplicidad: R6 es mucho más simple que RC. Mientras que ambos están construidos sobre entornos (environments), R6 utiliza el sistema S3, que es más sencillo y fácil de entender que el sistema S4 utilizado por RC. Documentación exhaustiva: R6 cuenta con una documentación completa en línea disponible en https://r6.r-lib.org. Esta documentación proporciona recursos detallados y ejemplos para comprender y utilizar R6 de manera efectiva. Subclases entre paquetes: R6 ofrece un mecanismo más simple para la subclases entre paquetes, que funciona automáticamente sin necesidad de que el usuario lo configure. Por el contrario, RC requiere más configuración y atención al detalle para lograr la misma funcionalidad. Separación de variables y campos: En RC, las variables y los campos se mezclan en la misma pila de entornos, lo que puede conducir a confusión y a errores potenciales. En R6, los campos se colocan en un entorno separado, lo que hace que el código sea más explícito y menos propenso a errores. Velocidad: R6 es mucho más rápido que RC en términos de tiempo de despacho de métodos. Aunque generalmente la velocidad de despacho de métodos no es crítica en aplicaciones del mundo real, RC es notablemente más lento, y el cambio de RC a R6 ha llevado a mejoras sustanciales de rendimiento en el paquete Shiny. Independencia de la versión de R: RC está ligado a una versión específica de R. Esto significa que cualquier corrección de errores en RC solo se puede aprovechar si se requiere una versión más reciente de R. Esto puede dificultar la compatibilidad entre paquetes que necesitan funcionar en diferentes versiones de R. 3.5 Ejercicios prácticos Create a bank account R6 class that stores a balance and allows you to deposit and withdraw money. Create a subclass that throws an error if you attempt to go into overdraft. Create another subclass that allows you to go into overdraft, but charges you a fee. CuentaBanco &lt;- R6Class(&quot;CuentaBanco&quot;, private = list( saldo = 0 ), active = list( .saldo = function(value){ if (missing(value)) { private$saldo } else { stop(&quot;`$saldo` solo se puede leer NO modificar&quot;, call. = FALSE) } } ), public = list( initialize = function(x=0){ private$saldo &lt;- x }, depositar = function(x){ private$saldo &lt;- private$saldo + x invisible(self) }, retirar = function(x){ private$saldo = private$saldo - x invisible(self) }, print = function(...){ cat(&quot;Cuenta: \\n&quot;) cat(&quot; Saldo: &quot;, private$saldo, &quot;\\n&quot;, sep = &quot;&quot;) } ) ) SubCuentaBanco1 &lt;- R6Class(&#39;SubCuentaBanco1&#39;, inherit = CuentaBanco, public = list( retirar = function(x){ stopifnot(&quot;Existe sobregiro&quot;= super$.saldo-x&gt;=0) private$saldo&lt;-super$retirar(x)$.saldo } ) ) SubCuentaBanco2 &lt;- R6Class(&#39;SubCuentaBanco2&#39;, inherit = CuentaBanco, public = list( retirar = function(x){ if(super$.saldo-x&lt;0){ private$saldo &lt;- super$retirar(x)$.saldo - 1 #Cargo extra 1 } else{private$saldo &lt;- super$retirar(x)$.saldo} } ) ) Fab &lt;- CuentaBanco$new(100) Fab ## Cuenta: ## Saldo: 100 Fab$retirar(50) Fab ## Cuenta: ## Saldo: 50 Fab$depositar(10) Fab ## Cuenta: ## Saldo: 60 Fab2&lt;-SubCuentaBanco1$new(100) Fab2 ## Cuenta: ## Saldo: 100 Fab2$retirar(150) ## Error in Fab2$retirar(150): Existe sobregiro Fab2 ## Cuenta: ## Saldo: 100 Fab3 &lt;- SubCuentaBanco2$new(100) Fab3 ## Cuenta: ## Saldo: 100 Fab3$retirar(150) Fab3 ## Cuenta: ## Saldo: -51 Create an R6 class that represents a shuffled deck of cards. You should be able to draw cards from the deck with $draw(n), and return all cards to the deck and reshuffle with $reshuffle(). Use the following code to make a vector of cards. library(R6) cartas &lt;- R6Class(&#39;cartas&#39;, private = list( suit = c(&quot;♠&quot;, &quot;♥&quot;, &quot;♦&quot;, &quot;♣&quot;), val = c(&quot;A&quot;, c(2:10), &quot;J&quot;, &quot;Q&quot;, &quot;K&quot;) ), public = list( cards = c(paste0(rep(c(&quot;A&quot;, c(2:10), &quot;J&quot;, &quot;Q&quot;, &quot;K&quot;), 4), c(&quot;♠&quot;, &quot;♥&quot;, &quot;♦&quot;, &quot;♣&quot;))), drawn = function(n){ self$cards &lt;- self$cards[-n] invisible(self) }, reshuffle=function(){ copy &lt;- paste0(rep(private$val, 4), private$suit) x&lt;-sample(52) for (i in 1:52) { self$cards[i]&lt;-copy[x[i]] } invisible(self) } ), active=list( .cartas=function(value){ if(missing(value)){ self$cards } else{stop(&quot;`Cartas` solo se puede leer NO modificar&quot;, call. = FALSE)} } ) ) mazo&lt;-cartas$new() mazo$.cartas ## [1] &quot;A♠&quot; &quot;2♥&quot; &quot;3♦&quot; &quot;4♣&quot; &quot;5♠&quot; &quot;6♥&quot; &quot;7♦&quot; &quot;8♣&quot; &quot;9♠&quot; &quot;10♥&quot; &quot;J♦&quot; &quot;Q♣&quot; ## [13] &quot;K♠&quot; &quot;A♥&quot; &quot;2♦&quot; &quot;3♣&quot; &quot;4♠&quot; &quot;5♥&quot; &quot;6♦&quot; &quot;7♣&quot; &quot;8♠&quot; &quot;9♥&quot; &quot;10♦&quot; &quot;J♣&quot; ## [25] &quot;Q♠&quot; &quot;K♥&quot; &quot;A♦&quot; &quot;2♣&quot; &quot;3♠&quot; &quot;4♥&quot; &quot;5♦&quot; &quot;6♣&quot; &quot;7♠&quot; &quot;8♥&quot; &quot;9♦&quot; &quot;10♣&quot; ## [37] &quot;J♠&quot; &quot;Q♥&quot; &quot;K♦&quot; &quot;A♣&quot; &quot;2♠&quot; &quot;3♥&quot; &quot;4♦&quot; &quot;5♣&quot; &quot;6♠&quot; &quot;7♥&quot; &quot;8♦&quot; &quot;9♣&quot; ## [49] &quot;10♠&quot; &quot;J♥&quot; &quot;Q♦&quot; &quot;K♣&quot; mazo$drawn(1) mazo$.cartas ## [1] &quot;2♥&quot; &quot;3♦&quot; &quot;4♣&quot; &quot;5♠&quot; &quot;6♥&quot; &quot;7♦&quot; &quot;8♣&quot; &quot;9♠&quot; &quot;10♥&quot; &quot;J♦&quot; &quot;Q♣&quot; &quot;K♠&quot; ## [13] &quot;A♥&quot; &quot;2♦&quot; &quot;3♣&quot; &quot;4♠&quot; &quot;5♥&quot; &quot;6♦&quot; &quot;7♣&quot; &quot;8♠&quot; &quot;9♥&quot; &quot;10♦&quot; &quot;J♣&quot; &quot;Q♠&quot; ## [25] &quot;K♥&quot; &quot;A♦&quot; &quot;2♣&quot; &quot;3♠&quot; &quot;4♥&quot; &quot;5♦&quot; &quot;6♣&quot; &quot;7♠&quot; &quot;8♥&quot; &quot;9♦&quot; &quot;10♣&quot; &quot;J♠&quot; ## [37] &quot;Q♥&quot; &quot;K♦&quot; &quot;A♣&quot; &quot;2♠&quot; &quot;3♥&quot; &quot;4♦&quot; &quot;5♣&quot; &quot;6♠&quot; &quot;7♥&quot; &quot;8♦&quot; &quot;9♣&quot; &quot;10♠&quot; ## [49] &quot;J♥&quot; &quot;Q♦&quot; &quot;K♣&quot; mazo$reshuffle() mazo$.cartas ## [1] &quot;K♥&quot; &quot;A♦&quot; &quot;Q♣&quot; &quot;9♠&quot; &quot;10♦&quot; &quot;A♠&quot; &quot;9♥&quot; &quot;8♣&quot; &quot;K♠&quot; &quot;J♠&quot; &quot;3♥&quot; &quot;K♦&quot; ## [13] &quot;Q♠&quot; &quot;6♦&quot; &quot;8♠&quot; &quot;J♦&quot; &quot;7♣&quot; &quot;4♥&quot; &quot;3♦&quot; &quot;K♣&quot; &quot;8♦&quot; &quot;7♠&quot; &quot;7♥&quot; &quot;5♣&quot; ## [25] &quot;3♣&quot; &quot;9♦&quot; &quot;9♣&quot; &quot;J♣&quot; &quot;5♥&quot; &quot;2♥&quot; &quot;10♥&quot; &quot;Q♦&quot; &quot;10♠&quot; &quot;4♦&quot; &quot;5♦&quot; &quot;2♦&quot; ## [37] &quot;J♥&quot; &quot;8♥&quot; &quot;6♠&quot; &quot;A♣&quot; &quot;2♣&quot; &quot;10♣&quot; &quot;Q♥&quot; &quot;5♠&quot; &quot;4♠&quot; &quot;7♦&quot; &quot;A♥&quot; &quot;4♣&quot; ## [49] &quot;3♠&quot; &quot;2♠&quot; &quot;6♣&quot; &quot;6♥&quot; Create an R6 class that allows you to get and set the current time zone. You can access the current time zone with Sys.timezone() and set it with Sys.setenv(TZ = \"newtimezone\"). When setting the time zone, make sure the new time zone is in the list provided by OlsonNames(). ZonaHoraria &lt;- R6Class(&#39;ZonaHoraria&#39;, public = list( zona = Sys.timezone(), cambiar_zona=function(name){ stopifnot(&quot;No existe esa zona horaria&quot; = name %in% OlsonNames()) self$zona=Sys.setenv(TZ = name) }) ) zona &lt;- ZonaHoraria$new() zona$cambiar_zona(&#39;America/Guayaquil&#39;) zona ## &lt;ZonaHoraria&gt; ## Public: ## cambiar_zona: function (name) ## clone: function (deep = FALSE) ## zona: TRUE Sys.timezone() ## [1] &quot;America/Guayaquil&quot; Create an R6 class that manages the current working directory. It should have $get() and $set() methods. Directorio &lt;- R6Class(&#39;Directorio&#39;, public = list( get=function(){ getwd() }, set=function(path){ setwd(path) invisible(self) } ) ) direct &lt;- Directorio$new() direct$get() ## [1] &quot;C:/Users/Dell/OneDrive - Escuela Politécnica Nacional/Pasantías UDC/Libro_TidyQualityTools&quot; direct$set(&quot;C:/Users/Dell/OneDrive - Escuela Politécnica Nacional/Pasantías UDC&quot;) direct$get() ## [1] &quot;C:/Users/Dell/OneDrive - Escuela Politécnica Nacional/Pasantías UDC&quot; Create a class with a write-only $password field. It should have $check_password(password) method that returns TRUE or FALSE, but there should be no way to view the complete password. # install.packages(&quot;R6&quot;) library(R6) Bank_writeonly &lt;- R6Class(&quot;Bank_writeonly&quot;, private = list( user = NULL, password = NULL ), active = list( .password = function(x){ if(missing(x)){ stop(&quot;`$.password` solo permite cambiar tu contraseña, NO verla&quot;, call. = FALSE) } else{ private$password &lt;- x cat(&quot;Contraseña cambiada con éxito&quot;) } } ), public = list( initialize = function(.user, .password){ private$password &lt;- .password private$user &lt;- .user }, check_password = function(p){ if(private$password == p){ cat(&quot;Tu contraseña SI coincide con la ingresada&quot;, call. = FALSE)} else{ stop(&quot;Tu contraseña NO coincide con la ingresada&quot;)} }, print = function(...){ cat(&quot;Bienvenido al Banco \\n&quot;) cat(&quot;Tu cuenta se ha creado con el nombre de usuario:&quot;, private$user) } ) ) # Prueba Cuenta_Andrea &lt;- Bank_writeonly$new(&quot;AndreaBC&quot;, &quot;prueba123&quot;) # Print Cuenta_Andrea ## Bienvenido al Banco ## Tu cuenta se ha creado con el nombre de usuario: AndreaBC # Funcion Check_password Cuenta_Andrea$check_password(&quot;Nomeacuerdomicontraseña&quot;) ## Error in Cuenta_Andrea$check_password(&quot;Nomeacuerdomicontraseña&quot;): Tu contraseña NO coincide con la ingresada Cuenta_Andrea$check_password(&quot;prueba123&quot;) ## Tu contraseña SI coincide con la ingresada FALSE # .password Cuenta_Andrea$.password ## Error: `$.password` solo permite cambiar tu contraseña, NO verla Cuenta_Andrea$.password &lt;- &quot;NuevaContraseña&quot; ## Contraseña cambiada con éxito Extend the Rando class with another active binding that allows you to access the previous random value. Ensure that active binding is the only way to access the value. Rando &lt;- R6::R6Class(&quot;Rando&quot;, private = list(prev = NULL), active = list( random = function(value) { if (missing(value)) { private$prev &lt;- runif(1) private$prev } else { stop(&quot;Can&#39;t set `$random`&quot;, call. = FALSE) } }, previous = function(value) { if (missing(value)) { private$prev } else { stop(&quot;Can&#39;t set `$random`&quot;, call. = FALSE) } } ) ) x &lt;- Rando$new() x$random ## [1] 0.8585389 x$random ## [1] 0.2535019 x$previous ## [1] 0.2535019 "],["tidyquant.html", "Capítulo 4 TidyQuant 4.1 Compatibilidad de funciones 4.2 Poder Cuantitativo en Acción", " Capítulo 4 TidyQuant .scroll-100 { max-height: 100px; overflow-y: auto; background-color: inherit; } Existe una amplia gama de funciones de análisis cuantitativo útiles que funcionan con objetos de series temporales. El problema es que muchas de estas maravillosas funciones no funcionan con tipos de datos data.frame, ni con el flujo de trabajo de tidyverse. Por ello el paquete Tidyquant integra las funciones más útiles de los paquetes: xts, zoo, quantmod, TTR y `PerformanceAnalytics, por ello, este texto se centra en demostrar como se integran las funciones más importantes con los paquetes financieros cuantitativos.siguientes: Transmutar tq_transmute(): Esta funcion devuelve un nuevo ‘tidy data frame’, que normalmente tiene una periodicidad diferente a la de la entrada. Mutate tq_mutate(): Esta funcion agrega columanas al tidy data frame. Para ello, lo primero que haremos será cargar los paquetes correspondientes: # Cargar tidyquant, lubridate, xts, quantmod, TTR library(tidyverse) library(tidyquant) 4.1 Compatibilidad de funciones tq_transmute_fun_options() Devuelve una lista de funciones de mutación compatibles con cada paquete, para ello haremos una breve discusión de las opciones respecto a cada paquete. tq_transmute_fun_options() %&gt;% str() ## List of 5 ## $ zoo : chr [1:14] &quot;rollapply&quot; &quot;rollapplyr&quot; &quot;rollmax&quot; &quot;rollmax.default&quot; ... ## $ xts : chr [1:27] &quot;apply.daily&quot; &quot;apply.monthly&quot; &quot;apply.quarterly&quot; &quot;apply.weekly&quot; ... ## $ quantmod : chr [1:25] &quot;allReturns&quot; &quot;annualReturn&quot; &quot;ClCl&quot; &quot;dailyReturn&quot; ... ## $ TTR : chr [1:64] &quot;adjRatios&quot; &quot;ADX&quot; &quot;ALMA&quot; &quot;aroon&quot; ... ## $ PerformanceAnalytics: chr [1:7] &quot;Return.annualized&quot; &quot;Return.annualized.excess&quot; &quot;Return.clean&quot; &quot;Return.cumulative&quot; ... Para ello, accederemos a las funciones de los respectivos paquetes que tienen compatibilidad para trabarse con tq_transmute y tq_mutate a partir del comando “$”. 4.1.1 Funcionalidad zoo tq_transmute_fun_options()$zoo ## [1] &quot;rollapply&quot; &quot;rollapplyr&quot; &quot;rollmax&quot; ## [4] &quot;rollmax.default&quot; &quot;rollmaxr&quot; &quot;rollmean&quot; ## [7] &quot;rollmean.default&quot; &quot;rollmeanr&quot; &quot;rollmedian&quot; ## [10] &quot;rollmedian.default&quot; &quot;rollmedianr&quot; &quot;rollsum&quot; ## [13] &quot;rollsum.default&quot; &quot;rollsumr&quot; Las funciones del paquete zoo que son compatibles se enumerar arriba. EN términos generales, estas son: Funciones Roll Apply: Una función genérica para aplicar una función a los márgenes móviles. Forma: rollapply(data, width, FUN, ..., by = 1, by.column = TRUE, fill = if (na.pad) NA, na.pad = FALSE, partial = FALSE, align = c(\"center\", \"left\", \"right\"), coredata = TRUE) Las opciones incluyen: rollmax, rollmean, rollmedian, rollsum, etc. 4.1.2 Funcionalidad xts tq_transmute_fun_options()$xts ## [1] &quot;apply.daily&quot; &quot;apply.monthly&quot; &quot;apply.quarterly&quot; &quot;apply.weekly&quot; ## [5] &quot;apply.yearly&quot; &quot;diff.xts&quot; &quot;lag.xts&quot; &quot;period.apply&quot; ## [9] &quot;period.max&quot; &quot;period.min&quot; &quot;period.prod&quot; &quot;period.sum&quot; ## [13] &quot;periodicity&quot; &quot;to.daily&quot; &quot;to.hourly&quot; &quot;to.minutes&quot; ## [17] &quot;to.minutes10&quot; &quot;to.minutes15&quot; &quot;to.minutes3&quot; &quot;to.minutes30&quot; ## [21] &quot;to.minutes5&quot; &quot;to.monthly&quot; &quot;to.period&quot; &quot;to.quarterly&quot; ## [25] &quot;to.weekly&quot; &quot;to.yearly&quot; &quot;to_period&quot; Las funciones del paquete xts que son compatibles están enumeradas arribas. en términos generales, son: Funciones Period Apply: Aplicar una función a un segmento de tiempo, por ejemplo: max, min, mean, etc. Forma: apply.daily(x, FUN, ...). Las opciones incluyen: apply.daily, weekly, monthly, quarterly, yearly. Funciones To-Period Functions: Convierte una serie de tiempo en un serie de tiempo de menor periodicidad, por ejemplo, convierte periodicidad diaria en mensual. Forma: to.period(x, period = 'months', k = 1, indexAt, name = NULL, OHLC = TRUE, ...). Las opciones incluyen: to.minutes, hourly, daily, weekly, monthly, quarterly, yearly. Es importante aclarar que: la estructura de devolución es diferente para to.period, to.monthly, to.weekly, to.quarterly, etc. to.period retorna la fecha, mientras que to.monthly devuelve un caracter de tipo “MON YYYY”. Es recomendable trabajaer con to.period, si se desea trabar con series temporales a través de lubridate. 4.1.3 Funcionalidad quantmod tq_transmute_fun_options()$quantmod ## [1] &quot;allReturns&quot; &quot;annualReturn&quot; &quot;ClCl&quot; &quot;dailyReturn&quot; ## [5] &quot;Delt&quot; &quot;HiCl&quot; &quot;Lag&quot; &quot;LoCl&quot; ## [9] &quot;LoHi&quot; &quot;monthlyReturn&quot; &quot;Next&quot; &quot;OpCl&quot; ## [13] &quot;OpHi&quot; &quot;OpLo&quot; &quot;OpOp&quot; &quot;periodReturn&quot; ## [17] &quot;quarterlyReturn&quot; &quot;seriesAccel&quot; &quot;seriesDecel&quot; &quot;seriesDecr&quot; ## [21] &quot;seriesHi&quot; &quot;seriesIncr&quot; &quot;seriesLo&quot; &quot;weeklyReturn&quot; ## [25] &quot;yearlyReturn&quot; Las funciones del paquete quantmod que son compatibles se enumeran arriba. En terminos generales, son : Funciones de cambio porcentual (Delt) y retrasos: Delt: Delt(x1, x2 = NULL, k = 0, type = c(\"arithmetic\", \"log\")) Variaciones de Delt: ClCl, HiCl, LoCl, LoHi, OpCl, OpHi, OpLo, OpOp Forma: OpCl(OHLC) Retrasos: Lag(x, k = 1) / Siguiente: Next(x, k = 1) (También puede usar dplyr::lag and dplyr::lead) Funciones de devolución del período: Se obtienen los rendimientos aritméticos o logarítmicos para diversas periodicidades, qué incluyen diaria, semanal, mensual, trimestral y anual. Forma: periodReturn(x, period = 'monthly', subset = NULL, type = 'arithmetic', leading = TRUE, ...) Funciones de Series: Devuelve valores que describen la serie, las opciones incluyen describir los aumentos o disminuciones, la aceleración o desaceleración y alto o bajo. Formas: seriesHi(x), seriesIncr(x, thresh = 0, diff. = 1L), seriesAccel(x). 4.1.4 Funcionalidad TTR tq_transmute_fun_options()$TTR ## [1] &quot;adjRatios&quot; &quot;ADX&quot; &quot;ALMA&quot; ## [4] &quot;aroon&quot; &quot;ATR&quot; &quot;BBands&quot; ## [7] &quot;CCI&quot; &quot;chaikinAD&quot; &quot;chaikinVolatility&quot; ## [10] &quot;CLV&quot; &quot;CMF&quot; &quot;CMO&quot; ## [13] &quot;CTI&quot; &quot;DEMA&quot; &quot;DonchianChannel&quot; ## [16] &quot;DPO&quot; &quot;DVI&quot; &quot;EMA&quot; ## [19] &quot;EMV&quot; &quot;EVWMA&quot; &quot;GMMA&quot; ## [22] &quot;growth&quot; &quot;HMA&quot; &quot;keltnerChannels&quot; ## [25] &quot;KST&quot; &quot;lags&quot; &quot;MACD&quot; ## [28] &quot;MFI&quot; &quot;momentum&quot; &quot;OBV&quot; ## [31] &quot;PBands&quot; &quot;ROC&quot; &quot;rollSFM&quot; ## [34] &quot;RSI&quot; &quot;runCor&quot; &quot;runCov&quot; ## [37] &quot;runMAD&quot; &quot;runMax&quot; &quot;runMean&quot; ## [40] &quot;runMedian&quot; &quot;runMin&quot; &quot;runPercentRank&quot; ## [43] &quot;runSD&quot; &quot;runSum&quot; &quot;runVar&quot; ## [46] &quot;SAR&quot; &quot;SMA&quot; &quot;SMI&quot; ## [49] &quot;SNR&quot; &quot;stoch&quot; &quot;TDI&quot; ## [52] &quot;TRIX&quot; &quot;ultimateOscillator&quot; &quot;VHF&quot; ## [55] &quot;VMA&quot; &quot;volatility&quot; &quot;VWAP&quot; ## [58] &quot;VWMA&quot; &quot;wilderSum&quot; &quot;williamsAD&quot; ## [61] &quot;WMA&quot; &quot;WPR&quot; &quot;ZigZag&quot; ## [64] &quot;ZLEMA&quot; Aquí hay una breve descripción de las funciones más populares de TTR: Índice de movimiento direccional de Welles Wilder: ADX(HLC, n = 14, maType, ...) Bandas de Bollinger: BBands(HLC, n = 20, maType, sd = 2, ...) Tasa de cambio/impulso: Tasa de cambio - ROC(x, n = 1, type = c(\"continuous\", \"discrete\"), na.pad = TRUE). Impulso/Momento - momentum(x, n = 1, na.pad = TRUE) Medias Móviles (maType): Media móvil simple - SMA(x, n = 10, ...) Media móvil exponencial - EMA(x, n = 10, wilder = FALSE, ratio = NULL, ...) Media móvil exponencial doble - DEMA(x, n = 10, v = 1, wilder = FALSE, ratio = NULL) Media móvil Ponderada - WMA(x, n = 10, wts = 1:n, ...) Media móvil elástica ponderada por volumen - EVWMA(price, volume, n = 10, ...) Media móvil exponencial de retardo cero - ZLEMA(x, n = 10, ratio = NULL, ...) Precio promedio móvil ponderado por volumen - VWAP(price, volume, n = 10, ...) Media móvil de longitud variable - VMA(x, w, ratio = 1, ...) Media móvil de Hull - HMA(x, n = 20, ...) Média Movil de Arnaud Legoux - ALMA(x, n = 9, offset = 0.85, sigma = 6, ...) Oscilador MACD: MACD(x, nFast = 12, nSlow = 26, nSig = 9, maType, percent = TRUE, ...) Índice de Fuerza Relativa: RSI(price, n = 14, maType, ...) runFun: runSum(x, n = 10, cumulative = FALSE): devuelve sumas durante una ventana móvil de n períodos. runMin(x, n = 10, cumulative = FALSE): devuelve mínimos durante una ventana móvil de n períodos. runMax(x, n = 10, cumulative = FALSE): devuelve máximos durante una ventana móvil de n períodos. runMean(x, n = 10, cumulative = FALSE): devuelve medias durante una ventana móvil de n períodos. runMedian(x, n = 10, non.unique = \"mean\", cumulative = FALSE): devuelve medianas durante una ventana móvil de n períodos. runCov(x, y, n = 10, use = \"all.obs\", sample = TRUE, cumulative = FALSE): devuelve covarianzas sobre una ventana móvil de n períodos. runCor(x, y, n = 10, use = \"all.obs\", sample = TRUE, cumulative = FALSE): devuelve correlaciones durante una ventana móvil de n períodos. runVar(x, y = NULL, n = 10, sample = TRUE, cumulative = FALSE): devuelve variaciones durante una ventana móvil de n períodos. runSD(x, n = 10, sample = TRUE, cumulative = FALSE): devuelve desviaciones estándar durante una ventana móvil de n períodos. runMAD(x, n = 10, center = NULL, stat = \"median\", constant = 1.4826, non.unique = \"mean\", cumulative = FALSE): devuelve las desviaciones absolutas mediana/media durante una ventana móvil de n períodos. wilderSum(x, n = 10): devuelve una suma ponderada al estilo de Welles Wilder sobre una ventana móvil de n períodos. Ocilador estocástico: stoch(HLC, nFastK = 14, nFastD = 3, nSlowD = 3, maType, bounded = TRUE, smooth = 1, ...) Índice de momento estocástico: SMI(HLC, n = 13, nFast = 2, nSlow = 25, nSig = 9, maType, bounded = TRUE, ...) 4.1.5 Funcionalidad PerformanceAnalytics tq_transmute_fun_options()$PerformanceAnalytics ## [1] &quot;Return.annualized&quot; &quot;Return.annualized.excess&quot; ## [3] &quot;Return.clean&quot; &quot;Return.cumulative&quot; ## [5] &quot;Return.excess&quot; &quot;Return.Geltner&quot; ## [7] &quot;zerofill&quot; Todas las funciones de mutación PerformanceAnalytics se ocupan de devoluciones: Return.annualized y Return.annualized.excess: toma los rendimientos del período y los consolida en rendimiento anualizados. Return.clean: elimina los valores atípicos de las devoluciones. Return.excess: elimina la tasa libre de riesgo de los rendimientos para generar rendimientos superiores a la tasa libre de riesgo. zerofill: Se utiliza para reemplazar valores NA con ceros. 4.2 Poder Cuantitativo en Acción Revisaremos algunos ejemplos, para ello utilizaremos la base de datos FANG, de datos que consta de los precios de las acciones de FB, AMZN, NFLX y GOOG desde principios de 2013 hasta finales del 2016. data(&quot;FANG&quot;) FANG ## # A tibble: 4,032 × 8 ## symbol date open high low close volume adjusted ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 FB 2013-01-02 27.4 28.2 27.4 28 69846400 28 ## 2 FB 2013-01-03 27.9 28.5 27.6 27.8 63140600 27.8 ## 3 FB 2013-01-04 28.0 28.9 27.8 28.8 72715400 28.8 ## 4 FB 2013-01-07 28.7 29.8 28.6 29.4 83781800 29.4 ## 5 FB 2013-01-08 29.5 29.6 28.9 29.1 45871300 29.1 ## 6 FB 2013-01-09 29.7 30.6 29.5 30.6 104787700 30.6 ## 7 FB 2013-01-10 30.6 31.5 30.3 31.3 95316400 31.3 ## 8 FB 2013-01-11 31.3 32.0 31.1 31.7 89598000 31.7 ## 9 FB 2013-01-14 32.1 32.2 30.6 31.0 98892800 31.0 ## 10 FB 2013-01-15 30.6 31.7 29.9 30.1 173242600 30.1 ## # ℹ 4,022 more rows 4.2.1 Ejemplo 1: utilizar quantmod periodReturn para convertir precios en rentabilidad La funcioón quantmod::periodReturn() genera retornos por periodicidad, para ello, revisemos algunos casos: 4.2.1.1 Ejemplo 1A: Obtener y registrar las rentabilidades anuales Utilizamos la columna de precios de cierre ajustados (ajustada para divisiones de acciones, lo que puede hacer que parezca que una acción tiene un mal desempeño si se incluye una división). Establecemos select = adjusted, investigamos la función periodReturn y descubrimos que acepta type = \"arithmetic\" y period = \"yearly\", que devuelve los rendimientos anuales. FANG_annual_returns &lt;- FANG %&gt;% group_by(symbol) %&gt;% tq_transmute(select = adjusted, mutate_fun = periodReturn, period = &quot;yearly&quot;, type = &quot;arithmetic&quot;) FANG_annual_returns ## # A tibble: 16 × 3 ## # Groups: symbol [4] ## symbol date yearly.returns ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 FB 2013-12-31 0.952 ## 2 FB 2014-12-31 0.428 ## 3 FB 2015-12-31 0.341 ## 4 FB 2016-12-30 0.0993 ## 5 AMZN 2013-12-31 0.550 ## 6 AMZN 2014-12-31 -0.222 ## 7 AMZN 2015-12-31 1.18 ## 8 AMZN 2016-12-30 0.109 ## 9 NFLX 2013-12-31 3.00 ## 10 NFLX 2014-12-31 -0.0721 ## 11 NFLX 2015-12-31 1.34 ## 12 NFLX 2016-12-30 0.0824 ## 13 GOOG 2013-12-31 0.550 ## 14 GOOG 2014-12-31 -0.0597 ## 15 GOOG 2015-12-31 0.442 ## 16 GOOG 2016-12-30 0.0171 Ahora, grafiquemos los redimientos anuales, a partir del uso rápido del paquete ggplot2: FANG_annual_returns %&gt;% ggplot(aes(x = date, y = yearly.returns, fill = symbol)) + geom_col() + geom_hline(yintercept = 0, color = palette_light()[[1]]) + scale_y_continuous(labels = scales::percent) + labs(title = &quot;FANG: Annual Returns&quot;, subtitle = &quot;Get annual returns quickly with tq_transmute!&quot;, y = &quot;Annual Returns&quot;, x = &quot;&quot;) + facet_wrap(~ symbol, ncol = 2, scales = &quot;free_y&quot;) + theme_tq() + scale_fill_tq() 4.2.1.2 Ejemplo 1B: Obtener devoluciones de registros diarios Los retornos de registros diarios siguen un enfoque similar. Normalmente se usa una función de transmutación tq_transmute porque la función periodReturn acepta diferentes opciones de periodicidad, y cualquier cosa que no sea diaria hará estallar una mutación. Sin embargo, en nuestro ejemplo, la periodicidad de los rendimientos es la misma que la periodicidad de los precios de las accciones (ambas diarias), por lo que podemos usar cualquiera de las dos funciones mencionadas anterioremente. Queremos utilizar la columna de precioes de cierre ajustados, para ello configuramos de manera similar al ejemplo anterior y obtenemos lo siguiente: FANG_daily_log_returns &lt;- FANG %&gt;% group_by(symbol) %&gt;% tq_transmute(select = adjusted, mutate_fun = periodReturn, period = &quot;daily&quot;, type = &quot;log&quot;, col_rename = &quot;monthly.returns&quot;) Y la gráfica, obtenida a partir del paquete ggplot2, se verá de la siguiente manera: FANG_daily_log_returns %&gt;% ggplot(aes(x = monthly.returns, fill = symbol)) + geom_density(alpha = 0.5) + labs(title = &quot;FANG: Charting the Daily Log Returns&quot;, x = &quot;Monthly Returns&quot;, y = &quot;Density&quot;) + theme_tq() + scale_fill_tq() + facet_wrap(~ symbol, ncol = 2) 4.2.2 Ejemplo 2: utilice xts to.period para cambiar la periodicidad de diaria a mensual La función xts::to.period se utiliza para convertir la periodicidad de un nivel inferior a un nivel superior (ej: meses a años). Dado que se busca una estructura que tenga una escala de tiempo diferente a la de entrada, se debe hacer una transformación. Utilizamos tq_transmute(), pasamos las columnas “open”, “high”, “low”, “close” y “volume”, y usamos el periodo “months”. FANG |&gt; group_by(symbol) |&gt; tq_transmute(select = open:volume, mutate_fun = to.period, period = &quot;months&quot;) ## # A tibble: 192 × 7 ## # Groups: symbol [4] ## symbol date open high low close volume ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 FB 2013-01-31 29.2 31.5 28.7 31.0 190744900 ## 2 FB 2013-02-28 26.8 27.3 26.3 27.2 83027800 ## 3 FB 2013-03-28 26.1 26.2 25.5 25.6 28585700 ## 4 FB 2013-04-30 27.1 27.8 27.0 27.8 36245700 ## 5 FB 2013-05-31 24.6 25.0 24.3 24.4 35925000 ## 6 FB 2013-06-28 24.7 25.0 24.4 24.9 96778900 ## 7 FB 2013-07-31 38.0 38.3 36.3 36.8 154828700 ## 8 FB 2013-08-30 42.0 42.3 41.1 41.3 67735100 ## 9 FB 2013-09-30 50.1 51.6 49.8 50.2 100095000 ## 10 FB 2013-10-31 47.2 52 46.5 50.2 248809000 ## # ℹ 182 more rows Podemos comparar la visualización gráfica agrupando y sin agrupas: Sin agregración de periodicidad FANG_diario &lt;- FANG |&gt; group_by(symbol) FANG_diario |&gt; ggplot(aes(x=date, y=adjusted, color = symbol))+ geom_line(linewidth = 1) + labs(title = &quot;Precio diario de acciones&quot;, x = &quot;&quot;, y = &quot;Precios ajustados&quot;, color = &quot;&quot;)+ facet_wrap(~ symbol, ncol = 2, scales = &quot;free_y&quot;)+ scale_y_continuous(labels = scales::dollar)+ theme_tq()+ scale_color_tq() Con agregación de periodicidad mensual FANG_mensual &lt;- FANG |&gt; group_by(symbol) |&gt; tq_transmute(select = adjusted, mutate_fun = to.period, period = &quot;months&quot;) FANG_mensual |&gt; ggplot(aes(x = date, y = adjusted, color = symbol)) + geom_line(linewidth = 1) + labs(title = &quot;Monthly Stock Prices&quot;, x = &quot;&quot;, y = &quot;Adjusted Prices&quot;, color = &quot;&quot;) + facet_wrap(~ symbol, ncol = 2, scales = &quot;free_y&quot;) + scale_y_continuous(labels = scales::dollar) + theme_tq() + scale_color_tq() Con esto se reduce la cantidad de puntos y el gráfico de la serie temporal se suaviza. 4.2.3 Ejemplo 3: utilice TTR runCor para visualizar correlaciones continuas de rendimientos Las correlaciones de rendimiento son una forma para analizar la medida en que un activo imita un índice de referencia. Utilizaremos los datos de FANG como los datos y la línea de base será el sector tecnológico “XLK”, para ello se recupera los precios utilizando tq_get, y los rendimientos se calculan a partir de los precios ajustados del Ejemplo 1 #Rendimientos FANG_rend_mensual &lt;- FANG |&gt; group_by(symbol) |&gt; tq_transmute(select = adjusted, mutate_fun = periodReturn, period = &quot;monthly&quot;) #Valor base de Rendimientos de referencia base_rend_mensual &lt;- &quot;XLK&quot; |&gt; tq_get(get = &quot;stock.prices&quot;, from = &quot;2013-01-01&quot;, to = &quot;2016-12-31&quot;) |&gt; tq_transmute(select = adjusted, mutate_fun = periodReturn, period = &quot;monthly&quot;) #Unir rends &lt;- left_join(FANG_rend_mensual, base_rend_mensual, by=&quot;date&quot;) rends ## # A tibble: 192 × 4 ## # Groups: symbol [4] ## symbol date monthly.returns.x monthly.returns.y ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 FB 2013-01-31 0.106 -0.0138 ## 2 FB 2013-02-28 -0.120 0.00782 ## 3 FB 2013-03-28 -0.0613 0.0258 ## 4 FB 2013-04-30 0.0856 0.0175 ## 5 FB 2013-05-31 -0.123 0.0279 ## 6 FB 2013-06-28 0.0218 -0.0289 ## 7 FB 2013-07-31 0.479 0.0373 ## 8 FB 2013-08-30 0.122 -0.0104 ## 9 FB 2013-09-30 0.217 0.0253 ## 10 FB 2013-10-31 -0.000398 0.0502 ## # ℹ 182 more rows La función runCor se puede utilizar para evaluar correlaciones rodantes, además se puede incluir el ancho de la correlación que en este caso utilizaremos seis al estar en una escala mensual. Se utilizará tq_transmute_xy para realizar esto: FANG_corr &lt;- rends |&gt; tq_transmute_xy(x = monthly.returns.x, y = monthly.returns.y, mutate_fun = runCor, n = 6, col_rename = &quot;corr_6&quot;) #Grafico FANG_corr |&gt; ggplot(aes(x = date, y = corr_6, color = symbol))+ geom_hline(yintercept = 0, color = palette_light()[[1]])+ geom_line(size = 1)+ labs(title = &quot;FANG: Correlación 6 meses a XLK&quot;, x=&quot;&quot;, y=&quot;Correlation&quot;,color=&quot;&quot;)+ facet_wrap(~symbol,ncol=2)+ theme_tq()+scale_color_tq() 4.2.4 Ejemplo 4: utilizar TTR::MACD para visualizar la divergencia y convergencia de la media móvil La función MACD nos da la convergencia y divergencia de la media móvil, vemos que la salida tiene la misma periodicidad que la entrada y las funciones funcionan con las de OHLC, por lo que se puede utilizar tq_mutate() FANG_macd &lt;- FANG |&gt; group_by(symbol) |&gt; tq_mutate(select = close, mutate_fun = MACD, nFast = 12, nSlow = 26, nSig = 9, maType = SMA) |&gt; mutate(diff = macd - signal) |&gt; select(-(open:volume)) FANG_macd ## # A tibble: 4,032 × 6 ## # Groups: symbol [4] ## symbol date adjusted macd signal diff ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 FB 2013-01-02 28 NA NA NA ## 2 FB 2013-01-03 27.8 NA NA NA ## 3 FB 2013-01-04 28.8 NA NA NA ## 4 FB 2013-01-07 29.4 NA NA NA ## 5 FB 2013-01-08 29.1 NA NA NA ## 6 FB 2013-01-09 30.6 NA NA NA ## 7 FB 2013-01-10 31.3 NA NA NA ## 8 FB 2013-01-11 31.7 NA NA NA ## 9 FB 2013-01-14 31.0 NA NA NA ## 10 FB 2013-01-15 30.1 NA NA NA ## # ℹ 4,022 more rows Y se puede graficar los datos de la siguiente forma: FANG_macd %&gt;% filter(date &gt;= as_date(&quot;2016-10-01&quot;)) %&gt;% ggplot(aes(x = date)) + geom_hline(yintercept = 0, color = palette_light()[[1]]) + geom_line(aes(y = macd, col = symbol)) + geom_line(aes(y = signal), color = &quot;blue&quot;, linetype = 2) + geom_bar(aes(y = diff), stat = &quot;identity&quot;, color = palette_light()[[1]]) + facet_wrap(~ symbol, ncol = 2, scale = &quot;free_y&quot;) + labs(title = &quot;FANG: Convergencia y Divergencia de la Media Móvil&quot;, y = &quot;MACD&quot;, x = &quot;&quot;, color = &quot;&quot;) + theme_tq() + scale_color_tq() 4.2.5 Ejemplo 5: utilizar xts::apply.quarterly para obtener el precio máximo y mínimo para cada trimestre La función xts::apply.quarterly() se puede utilizar para aplicar funciones por segmentos de tiempos trimestrales. Debido a que se va a usar una escala diferente a la de entrada (diaria) se necesita la función de transmutación tq_transmute, en la cual se configura en el argumento FUN= max para obtener los precios máximos de cierre durante el trimestre y en el argumento mutate_fun se escribe la función a aplicar por segmentos. FANG_maxtrim &lt;- FANG |&gt; group_by(symbol) |&gt; tq_transmute(select = adjusted, mutate_fun = apply.quarterly, FUN = max, col_rename = &quot;max.close&quot;) |&gt; mutate(year.qtr = paste0(year(date), &quot;-Q&quot;, quarter(date))) |&gt; select(-date) FANG_maxtrim ## # A tibble: 64 × 3 ## # Groups: symbol [4] ## symbol max.close year.qtr ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 FB 32.5 2013-Q1 ## 2 FB 29.0 2013-Q2 ## 3 FB 51.2 2013-Q3 ## 4 FB 58.0 2013-Q4 ## 5 FB 72.0 2014-Q1 ## 6 FB 67.6 2014-Q2 ## 7 FB 79.0 2014-Q3 ## 8 FB 81.4 2014-Q4 ## 9 FB 85.3 2015-Q1 ## 10 FB 88.9 2015-Q2 ## # ℹ 54 more rows y para obtener los precios mínimos se cambia el argumento FUN = min, además se pueden unir para obtenerlos en una misma salida: FANG_mintrim &lt;- FANG |&gt; group_by(symbol) |&gt; tq_transmute(select = adjusted, mutate_fun = apply.quarterly, FUN = min, col_rename = &quot;min.close&quot;) |&gt; mutate(year.qtr = paste0(year(date), &quot;-Q&quot;, quarter(date))) |&gt; select(-date) FANG_trim &lt;- left_join(FANG_maxtrim,FANG_mintrim, by=c(&quot;symbol&quot;=&quot;symbol&quot;,&quot;year.qtr&quot;=&quot;year.qtr&quot;)) FANG_trim ## # A tibble: 64 × 4 ## # Groups: symbol [4] ## symbol max.close year.qtr min.close ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 FB 32.5 2013-Q1 25.1 ## 2 FB 29.0 2013-Q2 22.9 ## 3 FB 51.2 2013-Q3 24.4 ## 4 FB 58.0 2013-Q4 44.8 ## 5 FB 72.0 2014-Q1 53.5 ## 6 FB 67.6 2014-Q2 56.1 ## 7 FB 79.0 2014-Q3 62.8 ## 8 FB 81.4 2014-Q4 72.6 ## 9 FB 85.3 2015-Q1 74.1 ## 10 FB 88.9 2015-Q2 77.5 ## # ℹ 54 more rows Para la visualización de los datos podemos realizar lo siguiente: FANG_trim |&gt; ggplot(aes(x=year.qtr,color=symbol))+ geom_segment(aes(xend=year.qtr,y=min.close,yend=max.close),linewidth=1)+ geom_point(aes(y = max.close), size = 2) + geom_point(aes(y = min.close), size = 2) + facet_wrap(~ symbol, ncol = 2, scale = &quot;free_y&quot;) + labs(title = &quot;FANG: Precio máximo y mínimo por trimestre&quot;, y = &quot;Precio de acción&quot;, color = &quot;&quot;) + theme_tq() + scale_color_tq() + scale_y_continuous(labels = scales::dollar) + theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.title.x = element_blank()) 4.2.6 Ejemplo 6: utilizar zoo::rollapply para visualizar una regresión continua En este ejemplo se analizará la relación entre dos activos similares: Mastercard y Visa, para mostrar la relación mediante regresión. Primero se verá la tendencia de los rendimientos, para ello utilizamos tq_get() para obtener los precios de las acciones, y tq_transmute() para transformar los precios en rendimientos. precios_accion &lt;- c(&quot;MA&quot;, &quot;V&quot;) %&gt;% tq_get(get = &quot;stock.prices&quot;, from = &quot;2015-01-01&quot;, to = &quot;2016-12-31&quot;) %&gt;% group_by(symbol) rend_accion &lt;- precios_accion %&gt;% tq_transmute(select = adjusted, mutate_fun = periodReturn, period = &quot;daily&quot;, type = &quot;log&quot;, col_rename = &quot;returns&quot;) %&gt;% spread(key = symbol, value = returns) #GRAFICOS rend_accion %&gt;% ggplot(aes(x=V,y=MA)) + geom_point(color = palette_light()[[1]], alpha = 0.5) + geom_smooth(method = &quot;lm&quot;) + labs(title = &quot;Relación de rendimiento de las acciones &quot;) + theme_tq() Se puede ver estadísticas de la relación a partir de la función lm: lm(MA~V,data = rend_accion) |&gt; summary() ## ## Call: ## lm(formula = MA ~ V, data = rend_accion) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.0269573 -0.0039659 0.0002149 0.0039648 0.0289463 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0001130 0.0003097 0.365 0.715 ## V 0.8133663 0.0226394 35.927 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.00695 on 502 degrees of freedom ## Multiple R-squared: 0.72, Adjusted R-squared: 0.7194 ## F-statistic: 1291 on 1 and 502 DF, p-value: &lt; 2.2e-16 La estimación del coeficiente es 0.8134 por lo que se tiene una relación positiva, es decir que a medida que V crece, MA aumenta. Se puede utilizar la funcion rollapply para realizar una regresión móvil, es decir, mostrar como el modelo varía a lo largo del tiempo. Para ello se creará una función: regr_fun &lt;- function(data){ coef(lm(MA~V,data=timetk::tk_tbl(data,silent=TRUE))) } y se utilizará tq_mutate() para aplicar la función de regresión creada utilizando rollapply de la siguiente forma: rend_accion &lt;- rend_accion |&gt; tq_mutate(mutate_fun = rollapply, width=90, FUN=regr_fun, by.column=FALSE, col_rename = c(&quot;coef.0&quot;,&quot;coef.1&quot;)) rend_accion ## # A tibble: 504 × 5 ## date MA V coef.0 coef.1 ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2015-01-02 0 0 NA NA ## 2 2015-01-05 -0.0285 -0.0223 NA NA ## 3 2015-01-06 -0.00216 -0.00646 NA NA ## 4 2015-01-07 0.0154 0.0133 NA NA ## 5 2015-01-08 0.0154 0.0133 NA NA ## 6 2015-01-09 -0.0128 -0.0149 NA NA ## 7 2015-01-12 -0.0129 -0.00196 NA NA ## 8 2015-01-13 0.00228 0.00292 NA NA ## 9 2015-01-14 -0.00108 -0.0202 NA NA ## 10 2015-01-15 -0.0146 -0.00955 NA NA ## # ℹ 494 more rows Para visualizar el primer coeficiente, se puede agregar una linea horizontal utilizando el modelo de conjunto de datos completo, ya que así se puede ver en que momentos se desvía de la tendencia a largo plazo. rend_accion |&gt; ggplot(aes(x=date,y=coef.1))+ geom_line(size=1,color=palette_light()[[1]])+ geom_hline(yintercept = 0.8134, size = 1, color = palette_light()[[2]])+ labs(title = &quot;MA ~ V: Visualizing Rolling Regression Coefficient&quot;, x = &quot;&quot;)+ theme_tq() Para visualizar la rentabilidad de las acciones durante el período de tiempo: precios_accion |&gt; tq_transmute(adjusted, periodReturn, period=&quot;daily&quot;, type=&quot;log&quot;, col_name=&quot;returns&quot;) |&gt; mutate(wealth.index = 100 * cumprod(1 + daily.returns)) %&gt;% ggplot(aes(x = date, y = wealth.index, color = symbol)) + geom_line(size = 1) + labs(title = &quot;MA and V: Stock Prices&quot;) + theme_tq() + scale_color_tq() 4.2.7 Ejemplo 7: utilizar return.clean y return.excess para limpiar y calcular el exceso de rendimiento En este ejemplo primero se calcula los rendimientos diarios utilizando periodReturn, luego se utiliza Return.clean para limpiar los valores atípico de los datos devueltos, en el que el parámetro alpha es el porcentaje de datos atípicos se va a limpiar. Por último, los rendimientos excedentes se calculan con la función Return.excess con el parámetro Rf que representa la tasa libre de riesgo. FANG %&gt;% group_by(symbol) %&gt;% tq_transmute(adjusted, periodReturn, period = &quot;daily&quot;) %&gt;% tq_transmute(daily.returns, Return.clean, alpha = 0.05) %&gt;% tq_transmute(daily.returns, Return.excess, Rf = 0.03 / 252) ## # A tibble: 4,032 × 3 ## # Groups: symbol [4] ## symbol date `daily.returns &gt; Rf` ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 FB 2013-01-02 -0.000119 ## 2 FB 2013-01-03 -0.00833 ## 3 FB 2013-01-04 0.0355 ## 4 FB 2013-01-07 0.0228 ## 5 FB 2013-01-08 -0.0124 ## 6 FB 2013-01-09 0.0525 ## 7 FB 2013-01-10 0.0231 ## 8 FB 2013-01-11 0.0133 ## 9 FB 2013-01-14 -0.0244 ## 10 FB 2013-01-15 -0.0276 ## # ℹ 4,022 more rows "],["qualitytools.html", "Capítulo 5 QualityTools 5.1 Fase 1: Definir 5.2 Fase 2: Medir 5.3 Fase 3: Analizar 5.4 Fase 4: Mejorar 5.5 Deseabilidades 5.6 Utilización de deseabilidades junto con experimentos diseñados 5.7 Diseños Taguchi", " Capítulo 5 QualityTools Este trabajo pretende dar una breve introducción a los métodos del paquete QualityTools. Este paquete se implementó con fines didácticos para servir como una “Caja de Herramientas” (Six-Sigma) y contiene métodos asociados con el ciclo de resolución con la metodología de: “Definir, Medir, Analizar, Mejorar y Controlar” (con sus siglas en inglés DMAIC). El uso de estos métodos se ilustran con ayuda de conjuntos de datos creados artificalmente, a continuación se explica, el objetivo de cada una de las fases de este ciclo: Definir: Describir el problema y sus consecuencias (financieras), es la etapa fundamental para delimitar el problema. Los diagramas de flujo. Los diagramas de flujo de procesos identifican elementos cruciales del proceso (es decir, actividades), las técnicas de creatividad como Brainwriting y Brainstorming, así como la técnica SIPOC4, deberían conducir, dependiendo del tamaño futuro del proyecto, a posiblemente una carta del proyecto. Medir: Elaborar un plan razonable para recopilar los datos requeridos y asegurarse de que los sistemas de medición sean capaces (es decir, ningún sesgo o sesgo conocido y la menor variación inmanente del sistema que contribuya a las mediciones como sea posible). Dentro de esta fase se proporciona una descripción de la situación con la ayuda de índices de capacidad de proceso o de medición (MSA5 Tipo I) o un Gage R&amp;R (MSA Tipo II) Analizar: Intente encontrar las causas fundamentales del problema utilizando varios métodos estadísticos, como histogramas, regresión, correlación, identificación de distribución, análisis de varianza y gráficos multivariados. Mejorar: Utiliza experimentos diseñados, es decir, factoriales completos y fraccionarios, diseños de superficies de respuesta, diseños de mezclas, diseños de taguchi y el concepto de deseabilidad para encontrar configuraciones o soluciones óptimas para un problema. Controlar: Una vez que se logró una mejora, es necesario asegurarla, lo que significa que se deben implementar acuerdos para garantizar el nivel de mejora. El uso de control estadístico de procesos (es decir, gráficos de control de calidad) se puede utilizar para monitorear el comportamiento de un proceso 5.1 Fase 1: Definir La mayoría de las técnicas utilizadas en esta fase no están relacionadas con el uso sustancial de métodos estadísticos. Su objetivo es captar los conocimientos e ideas sobre el proceso involucrado, establecer un objetivo común y definir cómo cada parte contribuye a la solución. Una técnica de visualización clásica que se utiliza en esta fase y está disponible en el paquete QualityTools es el Diagrama de Pareto, que nos ayuda a separar las pocas causas vitales de las muchas causas triviales. Por ejemplo, en la causa más frecuente de un producto defectuoso, el diagrama de Pareto nos ayuda a visualizar cuánto contribuye una causa a un problema. Supongamos que una empresa está investigando unidades (productos) que no cumplen. 120 unidades fueron investigadas y se encontraron 6 tipos diferentes de defectos (datos cualitativos). Los defectos son denominados de A a F por fines prácticos. defectos = c(rep(&quot;E&quot;,62),rep(&quot;B&quot;,15),rep(&quot;F&quot;,3),rep(&quot;A&quot;,10),rep(&quot;C&quot;,20),rep(&quot;D&quot;,10)) paretoChart(defectos) En este diagrama de Pareto podría transmitir el mensaje de que para resolver el \\(68\\%\\) de los problemas, el \\(33 \\%\\) de las causas (menos vitales) necesitan ser objeto de investigación. Además de este uso, los diagramas de Pareto también se utilizan para visualizar los tamaños de efectos de los diferentes factores para los experimentos diseñados, a continución se muestra un ejemplo de una gráfica de errores de medición. 5.2 Fase 2: Medir La recopilación de datos implica el uso de sistemas de medición a menudo denominados calibres. Para hacer una declaración sobre la calidad, el sistema de medición utilizado debe ser validado, y por lo tanto la variación para repetidas mediciones de la misma unidad debe ser tolerable, y por supuesto, debe depender del número de categorías distintivas qque necesita para poder identificar y caracterizar el producto. Esta cantidad tolerable de variación para un sistema de medición se relaciona directamente al rango de tolerancia de las características de un producto. La capacidad de un sistema de mediciones es crucial para cualquier conclusión basada en datos y está directamente relacionada con los costos que implican los errores tipo I y tipo II. 5.2.1 Capacidad de calibre - MSA Tipo I Supongamos que un ingeniero quiere comprobar la capacidad de un dispositivo de medición óptico. Una unidad con característica conocida (\\(x_m = 10.033mm\\)) se mide repetidamente \\(n=25\\) veces. De los valores de medición se obtiene la media \\(\\bar{x_g}\\) y la desviación estándar \\(s_g\\). Basicamente el cálculo de un índice de capacidad comprende dos pasos: primero se calcula una fracción del ancho de toletancia (es decir, \\(USL - LSL\\)), la fracción típicamente se relaciona a \\(0.2\\). En un segundo paso esta fracción se relaciona con una medida de la dispersión del proceso (es decir, el rango en el que el \\(95,5\\%\\), o el \\(99.73\\%\\) de las características de un proceso son esperados). Para valores de medición distribuidos normalmentem esto se relaciona con \\(k = 2 \\sigma_g\\) y \\(k = 3 \\sigma_g\\) calculados a partir de llos valores de medición; y para datos que no están distribuidos normalmente, se pueden tomar los cuantiles correspondientes. Si no hay sesgo, este cálculo representa el índice de capacidad \\(c_g\\) y refleja la verdadera capacidad del dispositivo de medición. \\[ \\begin{aligned} c_g &amp;= \\frac{0.2 \\cdot (USL - LSL)}{6 \\cdot s_g} \\\\ &amp;= \\frac{0.2 \\cdot (USL - LSL)}{X_{0.99865} - X_{0.00135}} \\end{aligned} \\] Sin embargo, si hay un sesgom se tiene en cuenta al restarlo del numerador, en este caso, \\(c_g\\) refleja solo la capacidad potencial (es decir, la capacidad si se corrige el sesgo), y \\(c_{gk}\\) es un estimador de la capacidad real. El sesgo se calcula como la diferencia entre la característica conocida \\(x_m\\) y la media de los valoes de medición \\(x_g\\). \\[ c_{gk} = \\frac{0.1 \\cdot (USL - LSL) - |x_m - x_g|}{3 \\cdot s_g} \\] Determinar si el sesgo se debe al azar o no, se puede hacer con la ayuda de una prueba t que tiene la forma general siguiente: \\[ t = \\frac{diferencia de medias}{error estandar de la diferencia} = \\frac{Dif}{s_{Dif}/\\sqrt{n}} \\] Además del sesgo y la desviación estándar, es importante comprobar el diagrama de ejecución de los valores de medición. Usando el paquete QualityTools, todo esto se logra fácilmente usando el método cg, su resultado se muestra a continuación: library(qualityTools) x &lt;- c ( 9.991, 10.013, 10.001, 10.007, 10.010, 10.013, 10.008, 10.017, 10.005, 10.005, 10.002, 10.017, 10.005, 10.002, 9.996, 10.011, 10.009 , 10.006, 10.008, 10.003, 10.002, 10.006, 10.010, 9.992, 10.013) cg(x, target = 10.003, tolerance = c(9.903, 10.103)) 5.2.2 Repetibilidad y reproducibidad del calibre - MSA Tipo II Un procedimineto común aplicado en la industria es realizar un análisis Gage R&amp;R para evaluar la repetibilidad y reproducibilidad de un sistema de medición (‘R&amp;R’ significa repetibilidad y reproducibilidad). La repetibilidad se refiere a la precisión de un sistema de medición, es decir, a la desviación estándar de mediciones posteriores de la misma unidad. miestras que reproducibilidad es la parte de la varianza general que modela el efecto de diferentes, por ejemplo, operadores que realizan mediciones en la misma unidad y una posible interacción entre diferentes operadores y piezas medidas dentro de este “Gage R&amp;R”, el modelo general está dado por: \\[ \\sigma^2_{total} = \\sigma^2_{Piezas} + \\sigma^2_{Operadores} + \\sigma^2_{Piezas \\times Operador} + \\sigma^2_{Error} \\] Donde: \\(\\sigma^2_{Piezas}\\): modela la variación entre diferentes unidades de un mismo proceso, por lo tanto, \\(\\sigma\\) es una estimación de la variabilidad inherente del proceso. $^2_{Operador} + ^2_{Piezas Operador} $: modela la reproducibilidad. \\(\\sigma^2_{Error}\\): modela la repetibilidad. Ahora, supongamos que 3 operadores elegidos al azar midieron 10 unidades elegidas al azar. Cada operador midió cada unidad dos veces en un orden elegido al azar y las unidades no puedes distingirse entre si. El Diseño R&amp;R del Calibre correspondiente se puede crear utilizando el método gageRRDesign del paquete QualityTools, y las medidas se asignan a este diseño utilizando el método de respuesta, dados por gageRR y plot. library(qualityTools) # Crear un diseño R&amp;R de Calibre dis &lt;- gageRRDesign(Operators = 3, Parts = 10, Measurements = 2, randomize = FALSE) # Establecemos las respuestas de medición response(dis) &lt;- c(23, 22, 22, 22, 22, 25, 23, 22, 23, 22, 20, 22, 22, 22, 24, 25, 27, 28, 23, 24, 23, 24, 24, 22, 22, 22, 24, 23, 22, 24, 20, 20, 25, 24, 22, 24, 21, 20, 21, 22, 21, 22, 21, 21, 24, 27, 25, 27, 23, 22, 25, 23, 23, 22, 22, 23, 25, 21, 24, 23) # Realizamos Gage R&amp;R gdo &lt;- gageRR_abc(dis) ## ## AnOVa Table - crossed Design ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Operator 2 20.63 10.317 8.597 0.00112 ** ## Part 9 107.07 11.896 9.914 7.31e-07 *** ## Operator:Part 18 22.03 1.224 1.020 0.46732 ## Residuals 30 36.00 1.200 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ---------- ## AnOVa Table Without Interaction - crossed Design ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Operator 2 20.63 10.317 8.533 0.000675 *** ## Part 9 107.07 11.896 9.840 2.39e-08 *** ## Residuals 48 58.03 1.209 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ---------- ## ## Gage R&amp;R ## VarComp VarCompContrib Stdev StudyVar StudyVarContrib ## totalRR 1.664 0.483 1.290 7.74 0.695 ## repeatability 1.209 0.351 1.100 6.60 0.592 ## reproducibility 0.455 0.132 0.675 4.05 0.364 ## Operator 0.455 0.132 0.675 4.05 0.364 ## Operator:Part 0.000 0.000 0.000 0.00 0.000 ## Part to Part 1.781 0.517 1.335 8.01 0.719 ## totalVar 3.446 1.000 1.856 11.14 1.000 ## ## --- ## * Contrib equals Contribution in % ## **Number of Distinct Categories (truncated signal-to-noise-ratio) = 1 # Visualización de Gage R&amp;R plot(gdo) El diagrama de barras ofrece una representación visual de los componentes de la varianza. totalRR representa la repetibilidad y reproducibilidad totales. El \\(48\\%\\) de la variación se debe al \\(35\\%\\) de repitibilidad, es decir, variación del propio calibre, y al \\(13\\%\\) de reproducibilidad, es decir, efecto del operador y la interación entre el operador y la pieza. Se puede ver en la tabla Anova que no existe interacción entre piezas y operadores. El \\(52\\%\\) de la variación (columna VarCompContrib) se debe a diferencias entre las partes tomadas del proceso (variación inherente), que se puede ver en el gráfico Measurement by Part. La variación de las mediciones tomadas por un operador es aproximadamente igual para los tres operadores (Measurement by Operator), aunque el operador C parece producir valores que la mayoría de las veces son mayores que los valores de los otros operadores (Interaction Operator: Part). Además de esta interpretación de los resultados, en la industria se utilizan valores críticos para totalRR, también denominado en la industria como “GRR”. Sin embargo, un sistema de medición nunca debe juzgarse únicamente por sus valores críticos. Contribución total RR Capacidad ≤ 0.1 Adecuada &lt; 0.1 y &lt; 0.3 Adecuada con limitaciones dependiendo de las circunstancias ≥ 0.3 No adecuada Verificación de interacción: El gráfico de interacción proporciona una verificación visual de posibles interacciones entre el Operador y la Pieza. Para cada operador se muestra el valor medio de la medición en función del número de pieza. Las líneas cruzadas indican que los operadores están asignando lecturas diferentes a idénticas dependiendo de la combinación de Operador y Pieza. Diferentes lecturas significan, en el caso de una interacción entre Operador y Pieza, que en promedio a veces se asignan valores más pequeños o más grandes dependiendo de la combinación de Operador y Pieza. En este caso, las líneas prácticamente no se cruzan, pero el operador C parece asignar sistemáticamente lecturas mayores a las piezas que sus colegas. Operadores: Para comprobar si hay un efecto dependiente del operador, las mediciones se trazan agrupadas por operadores en forma de diagramas de caja. Los diagramas de caja que difieren en tamaño o ubicación pueden indicar, por ejemplo, posibles procedimientos diferentes dentro del proceso de medición, que luego conducen a una diferencia sistemática en las lecturas. En nuestro ejemplo se podría discutir un posible efecto para el operador C que también está respaldado por el gráfico de interacción. Variación inherente del proceso: Dentro de este gráfico las mediciones están agrupadas por operador. Gracias a las mediciones repetidas realizadas por diferentes operadores por pieza, se obtiene una idea del proceso. Una línea que conecta la media de las mediciones de cada parte proporciona una idea de la variación inherente del proceso. Cada pieza se mide el número de operadores multiplicado por el número de mediciones por pieza. Componentes de Variación: Para comprender el resultado de un estudio de Gage R&amp;R se debe hacer referencia a la fórmula presentada al inicio de esta sección. El componente de varianza totalRR (columna VarComp) representa la repetibilidad y reproducibilidad total. Dado que las varianzas simplemente se suman, se tiene que \\(1.664\\) es la suma de \\(1.209\\) (repetibilidad dada por \\(\\sigma^2_{Error}\\)) y \\(0.455\\) (reproducibilidad) que es la suma de Operador (\\(\\sigma^2_{Operador}\\)) y Operador:Parte (\\(\\sigma^2_{Partes \\times Operador}\\)). Como no hay interacción, la reproducibilidad asciende a \\(0.455\\). Parte a Parte asciende a \\(1.781\\). Junto con el total de repetibilidad y reproducibilidad, esto da \\(\\sigma^2_{Total} = 3.446\\). 5.3 Fase 3: Analizar 5.3.1 Capacidad del Proceso Además de la capacidad de un sistema de medición, a menudo la capacidad de un proceso es de interés o necesidad que debe evaluarse, por ejemplo, como parte de una relación entre proveedor y cliente en la industria. Los índices de capacidad del proceso básicamente indican cuánto del rango de tolerancia está siendo utilizado por la variación debida a causas comunes del proceso considerado. Utilizando estas técnicas, se puede determinar cuántas unidades (por ejemplo, productos) se espera que caigan fuera del rango de tolerancia, es decir, defectuoso con respecto a los requisitos determinados. También proporciona información sobre dónde centrar el proceso si el desplazamiento es posible y significativo en términos de costos. \\[ c_p = \\frac{USL - LSL}{Q_{0.99865} - Q_{0.00135}} \\] \\[ c_{pkL} = \\frac{Q_{0.5} - LSL}{Q_{0.5} - Q_{0.00135}} \\] \\[ c_{pkU} = \\frac{USL - Q_{0.5}}{Q_{0.99865} - Q_{0.5}} \\] * \\(c_p\\): Es la capacidad potencial del proceso que podría lograrse si el proceso se pudiera centrar dentro de los límites de especificación. \\(c_{pk}\\): Es la capacidad real del proceso que incorpora la ubicación de la distribución (es decir, el centro) de la característica dentro de los límites de especificación. Para límites de especificación unilaterales, existen \\(c_{pkL}\\) y \\(c_{pkU}\\), siendo \\(c_{pk}\\) igual al índice de capacidad más pequeño. Como se puede imaginar, además de la ubicación de la distribución de la característica, la forma de la distribución también es relevante. Evaluar el ajuste de una distribución específica para datos dados se puede hacer a través de gráficos de probabilidad (ppPlot) y gráficos de cuantiles-cuantiles (qqPlot), así como métodos de prueba formales como la Prueba de Anderson-Darling. Las capacidades del proceso pueden calcularse con el método pcr del paquete qualityTools. El método pcr traza un histograma de los datos, la distribución ajustada y devuelve los índices de capacidad junto con los parámetros estimados de la distribución, una Prueba de Anderson-Darling para la distribución especificada y el correspondiente QQ-Plot. Ejemplos: Distribución Normal set.seed(1234) datos &lt;- rnorm(20, mean = 20) pcr(datos, &quot;normal&quot;, lsl = 17, usl = 23) ## Error in round(x$statistic, 4): non-numeric argument to mathematical function Distribución Weibull set.seed(1234) weib &lt;- rweibull(20, shape = 2, scale = 8) pcr(weib, &quot;weibull&quot;, usl = 20) ## Error in round(x$statistic, 4): non-numeric argument to mathematical function Junto con la representación gráfica se presenta un Test de Anderson Darling y se devuelve la distribución Los gráficos QQ-plot pueden obtenerse a partir del paquete QualityTools, de la siguiente forma: par(mfrow = c(1,2)) qqPlot(weib, &quot;weibull&quot;); qqPlot(datos, &quot;normal&quot;) Y los gráficos de probabilidad se pueden calcular con la función ppPlot del mismo paquete, de la siguiente manera: par(mfrow = c(1,2)) ppPlot(weib, &quot;weibull&quot;); ppPlot(datos, &quot;normal&quot;) 5.4 Fase 4: Mejorar 5.4.1 Diseños factoriales \\(2^{k}\\) El método facDesign diseña un modelo de k factores y 2 combinaciones por factor, el cual es llamado \\(2^k\\). Supondremos un ejemplo de un proceso que tiene 5 factores A, B, C, D y E, de los cuales tres se consideran relevantes para el rendimiento del proceso (A, B y C). set.seed(1234) dfac &lt;- facDesign(k = 3, centerCube = 4) names(dfac) &lt;- c(&#39;Facto 1&#39;, &#39;Factor 2&#39;, &#39;Factor 3&#39;) lows(df) &lt;- c(80,120,1) highs(fdo) &lt;- c(120,140,2) summary(dfac) El proceso se simula con el método simProc: #Primeros valores rend &lt;- simProc(x1=120,x2=140,x3=2) #valores completos rend = c(simProc(120,140,1),simProc(80,140,1),simProc(120,140,2),simProc(120,120,1),simProc(90,130,1.5),simProc(90,130,1.5),simProc(80,120,2),simProc(90,130,1.5),simProc(90,130,1.5),simProc(120,120,2),simProc(80,140,2),simProc(80,120,1)) Se asigna el rendimiento al diseño factorial: response(dfac) &lt;- rend Para el análisis del diseño se puede usar los métodos effectPlot, interactionPlot, lm, wirePlot, contourPlot. effectPlot(dfac, classic = TRUE) interactionPlot(dfac) Se puede usar el método de R lm, vemos a continuación: m1 &lt;- lm(rend ~ A*B*C, data=dfac) summary(m1) Se puede que ver que A, B y AB son significativos. También se puede obtener dos gráficas mediante paretoPlot y normalPlot del mismo paquete qualityTools. par(mfrow=c(1,2)) paretoPlot(dfac) normalPlot(dfac) La relación entre el factor A y el B se puede visualizar mediante una representación 3D mediante wirePlot y contourPlot par(mfrow=c(1,2)) wirePlot(A,B,rend,data=dfac) contourPlot(A,B,rend,data=dfac) 5.4.2 Diseños factoriales fraccionarios \\(2^{k-p}\\) Este diseño tiene \\(k\\) factores y se prueba en \\(2k-p\\) ejecuciones, por ejemplo para un diseño \\(2^{5-1}\\) se prueban cinco factores en 24 ejecuciones. Para realizar esto se utiliza el método fracDesign, vamos a realizar el ejemplo de un diseño \\(2^{3-1}\\), para ello se debe utilizar el argumento gen='C=AB', lo cual quiere decir que el efecto de C es equivalente al de AB: dfacfrac &lt;- fracDesign(k=3,gen=&#39;C=AB&#39;,centerCube = 4) Se puede obtener información específica del diseño mediante summary: summary(dfacfrac) Vemos que en el modelo se muestra que I=ABC y por lo tanto se cumplen las siguientes reglas: \\[\\begin{align} I\\times A&amp;=A\\\\ A\\times A&amp;=I\\\\ A\\times B&amp;=B\\times A \\end{align}\\] Para encontrar todos los efectos equivalentes se puede usar los comandos: aliasTable(dfacfrac) confounds(dfacfrac) Estos diseños se pueden generar asignando los generadores apropiados, el cual se puede elegir entre tabla predefinidas usando el método fracChoose y seleccionando el diseño deseado: fracChoose() 5.4.3 Diseños replicados y puntos centrales Se puede crear un diseño replicado con puntos centrales adicionales usando replicates y centerCube: dfac1 &lt;- facDesign(k = 3, centerCube = 2, replicates = 2) 5.4.4 Respuestas múltiples Se puede agregar vectores de respuesta al diseño con el método response. Por ejemplo, se crea una segunda respuesta y2 que se llena con números aleatorios y se agrega al objeto creado. set.seed(1234) y2 &lt;- rnorm(12,mean=120) response(dfac) &lt;- data.frame(yield,y2) Se puede visualizar en 3D con los métodos wirePlot y contourPlot especificando con form: par(mforw = c(1,2)) wirePlot(A, B, yield, data = dfac, form = &quot;yield~A+B+C+A*B&quot;) contourPlot(A, B, y2, data = fdo, form = &quot;y2~A+B+C+A*B&quot;) Se puede crear los gráficos con el tercer factor C en -1 y \\(C=1\\), de la forma: par(mfrow = c(1,2)) wirePlot(A, B, y2, data = dfrac, factors = list(C=-1), form = &quot;y2~A*B*C&quot;) wirePlot(A, B, y2, data = dfrac, factors = list(C=1), form = &quot;y2∼A∗B∗C&quot;) Si no se proporciona ninguna fórmula explícitamente, los métodos predeterminados son el ajuste completo o el que está almacenado en el objeto de diseño factorial. El almacenamiento del ajusto se puede realizar con el método fits y se utiliza cuando se trabaja con más de una respuesta. Además, se utiliza lm para analizar el diseño factorial fraccionario. fits(fdo) &lt;- lm(yield∼A+B, data = fdo) fits(fdo) &lt;- lm(y2∼A∗B∗C, data = fdo) fits(fdo) 5.4.5 Pasar a un entorno de proceso con un mayor rendimiento esperado Como el proceso puede ser modelado por una relación lineal se puede determinar un alto rendimiento fácilmente, esto se puede calcular gráficamente o utilizando el método steepAscent: sao &lt;- steepAscent(factors = c(&quot;A&quot;, &quot;B&quot;), response = &quot;yield&quot;, data = dfac, steps = 20) sao Como se estableció los valores reales anteriormente con los métodos highs y lows son mostrados como valores reales. Los valores de respuesta de sao pueden ser establecidos con el método response y graficados con plot predicted &lt;- simProc(sao[,5], sao[,6]) responde(sao) &lt;- predicted plot(sao, type=&#39;b&#39;, col=2) 5.4.6 Diseños de superficies de respuesta Se debe tener en cuenta que no todas las relaciones son lineales por lo cual para detectar y modelizar las relaciones no lineales se necesitan más de dos combinaciones por factor. Para averiguar si un diseño de superficie de respuesta es necesario (es decir, un diseño con más de dos combinaciones por factor) se puede comparar el valor esperado de la(s) variable(s) de respuesta con la(s) observada(s) utilizando puntos centrales . Cuanto mayor sea la diferencia entre los valores esperados, más improbable será que esta diferencia sea el resultado de ruido aleatorio. Bajo el contexto del ejercicio desarrollado en la sección de diseño factorial \\(2^{k}\\) utilizamos el método steepAscent de qualityTools para pasar a una mejor región del proceso. El centro de la nueva región de proceso está definido por 144 y 165 en valores reales la cual es el inicio del nuevo diseño. #Semilla set.seed(1234) fdo2 &lt;- facDesign(k = 2, centerCube = 3) names(fdo2) &lt;- c(&quot;Factor1&quot;, &quot;Factor2&quot;) lows(fdo2) &lt;- c(13, 4, 155) highs(fdo2) &lt;- c(15, 5, 175) el rendimiento se obtiene utilizando el simProc y se asigna al nuevo diseño con la ayuda del método genérico de response del paquete qualityTools rendimiento=c(simProc(134,175),simProc(144.5,165.5),simProc(155,155),simProc(144.5,165.5),simProc(155,175),simProc(144.5,165.5),simProc(134,155)) response(fdo2)=rendimiento Si se observan los gráficos de residuos, se apreciará una diferencia sustancial entre los valores esperados y los valores observados (podría realizarse una prueba de falta de ajuste para verificarlo). Para llegar a un modelo que describa la relación hay que añadir más puntos que se denominan la starportion del diseño de la superficie de respuesta. La adición de la starportion se realiza fácilmente utilizando el método starDesign del paquete qualityTools Por defecto, el valor de alfa se elige de forma que ambos criterios, ortogonalidad y rotatabilidad se cumplan . Se llama al método starDesign en el objeto de diseño factorial factorial fdo2. La llamada a rsdo le mostrará el diseño de superficie de respuesta resultante.Debe tener una porción cúbica que conste de 4 runs, 3 puntos centrales en la porción cúbica, 4 axiales y 3 puntos centrales en la porción de estrella (starportion). rsdo= starDesign( data =fdo2 ) rsdo StandOrd RunOrder Block A B rendimiento 3 3 1 1 -1.000 3769 7 7 2 1 0.000 7953 2 2 3 1 -1.000 7935 6 6 4 1 0.000 7865 4 4 5 1 1.000 NA 5 5 6 1 0.000 NA 1 1 7 1 -1.000 NA 8 8 8 2 -1.414 NA 9 9 9 2 1.000 NA 10 10 10 2 0.000 NA 11 11 11 2 0.000 NA 12 12 12 2 0.000 NA 13 13 13 2 0.000 NA 14 14 14 2 0.000 NA Utilizando el método estrella del paquete qualityTools se pueden ensamblar fácilmente diseños secuencialmente. Esta estrategia secuencial ahorra recursos pues, en comparación con empezar con diseño de superficie de respuesta desde el principio, la parte en estrella sólo se ejecuta si es realmente necesaria. Los rendimientos del proceso siguen estando dados por el método simProc. yield2 &lt;- c( yield, simProc(130, 165), simProc(155, 165), simProc(144, 155), simProc(144, 179), simProc(144, 165), simProc(144, 165), simProc(144, 165) ) response(rsdo) &lt;- yield2 Se ajusta un modelo cuadrático completo utilizando el método lm lm.3 &lt;- lm(yield2 ~ A*B + I(A^2) + I(B^2), data = rsdo) La superficie de respuesta puede visualizarse utilizando wirePlot y contourPlot. par(mfrow = c(1, 2)) wirePlot(A, B, yield2, form = &quot;yield2 ~ A*B + I(A^2) + I(B^2)&quot;, data = rsdo, theta = -70) contourPlot(A, B, yield2, form = &quot;yield2 ~ A*B + I(A^2) + I(B^2)&quot;, data = rsdo) Se compara los resultados de los diseños factorial y de superficie de respuesta con el proceso simulado. Se pueden crear diseños de superficie de respuesta utilizando el método rsmDesign. Por ejemplo un diseño con alfa = 1.633, 0 puntos centrales en la parte del cubo y 6 puntos centrales en la parte de la estrella con: fdo &lt;- rsmDesign(k = 3, alpha = 1.633, cc = 0, cs = 6) y el diseño se puede poner en orden estándar utilizando el método randomize con el argumento so=TRUE (es decir, orden estándar). cc significa centerCube y cs para centerStar. fdo &lt;- randomizeDesign(fdo, so = TRUE) Los diseños de superficie de respuesta también pueden elegirse a partir de una tabla utilizando el método rsmChoose. rsdo &lt;- rsmDesign() &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ### Montaje secuencial de diseños de superficie de respuesta ======= #### Montaje secuencial de diseños de superficie de respuesta &gt;&gt;&gt;&gt;&gt;&gt;&gt; 38aa7fcbe69006ca620167942eac17f3b64293c9 El ensamblaje secuencial es una característica importante de los diseños de superficie de respuesta. En función de de las características del diseño factorial (fraccional) puede aumentarse una porción de estrella utilizando el método starDesign. Una porción en estrella consta de recorridos axiales y puntos centrales opcionales (cs) en la parte axial a diferencia de los puntos centrales (cc) en la parteparte cúbica. fdo3 &lt;- facDesign(k = 6) rsdo &lt;- starDesign(alpha = &quot;orthogonal&quot;, data = fdo3) En caso de que no se entregue ningún diseño factorial (fraccional) al método starDesign, se devuelve una lista con data.frames que pueden asignarse al diseño factorial (fraccional) existente utilizando los métodos star, centerStar y centerCube. &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ### Aleatorización ======= #### Aleatorización &gt;&gt;&gt;&gt;&gt;&gt;&gt; 38aa7fcbe69006ca620167942eac17f3b64293c9 La aleatorización se consigue utilizando el método randomize. Es necesario suministrar una semilla aleatoria (random.seed) que es útil para tener el mismo orden de ejecución en cualquier máquina. randomize(fdo, random.seed = 123) El método randomize se puede utilizar para obtener un diseño en orden estándar con la ayuda del argumento so. randomizeDesign(fdo, so = TRUE) &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ### Bloqueo ======= #### Bloqueo &gt;&gt;&gt;&gt;&gt;&gt;&gt; 38aa7fcbe69006ca620167942eac17f3b64293c9 El bloqueo es otra característica relevante y puede conseguirse mediante el método de blocking. Bloquear un diseño a posteriori no siempre tiene éxito. Sin embargo, no es problemático durante el montaje secuencial. 5.5 Deseabilidades Muchos problemas requieren optimización simultánea de más de una variable de respuesta. La optimización puede lograrse maximizando o minimizando el valor de la respuesta o tratando de situar la respuesta en un objetivo específico.En la Optimización mediante el enfoque de las deseabilidades Derringer y Suich [1980], los valores (predichos) de las variables de respuesta se transforman en valores dentro del intervalo [0,1] utilizando tres métodos de deseabilidad diferentes para los tres criterios de optimización diferentes (es decir, minimizar, maximizar, objetivo). A cada valor de una variable de respuesta se le puede asignar una deseabilidad específica, optimizando más de una variable de respuesta. La media geométrica de las deseabilidades específicas caracteriza la deseabilidad global. \\[\\sqrt[n]{\\prod^n_{i=1}d_i}\\] Para los valores previstos de las respuestas, cada combinación de factores tiene una correspondiente deseabilidad específica y se puede calcular una deseabilidad global. Supongamos que tenemos tres respuestas. Para un ajuste específico de los factores, las respuestas tienen deseabilidades como \\(d1 = 0,7\\) para \\(y1, d2 = 0,8\\) para \\(y2\\) y \\(d3 = 0,2\\) para \\(y3\\). La deseabilidad global viene dada por la media geométrica. \\[d_{all}=\\sqrt[n]{d_1d_2\\ldots d_n}\\] \\[=\\sqrt[3]{d_1d_2\\ldots d_n}\\] \\[=\\sqrt[n]{0.7\\cdot0.8\\cdot0.2}\\] Los métodos de deseabilidad pueden definirse mediante el método desires. La dirección de optimización de cada variable de respuesta se define mediante los argumentos min,max y target del método desires. El argumento target se establece con max para la maximización, min para la minimización y un valor específico para la optimización hacia un objetivo concreto. De esta constelación surgen tres ajustes: target = max: min es el valor mínimo aceptable. Si la variable de respuesta toma valores por debajo de min, la deseabilidad correspondiente será cero. Para valores iguales o mayores que min, la deseabilidad será mayor que cero. target = min: max es el valor máximo aceptable. Si la variable de respuesta toma valores por encima de max, la deseabilidad correspondiente será cero. Para valores iguales o menores que max, la deseabilidad será mayor que cero. target = valor: una variable de respuesta con un valor de valor se relaciona con la deseabilidad más alta alcanzable de 1. Los valores fuera de min o max llevan a una deseabilidad de cero, dentro de min y max a valores dentro de (0,1]. #EJEMPLO: d1 &lt;- desirability(y1, 120, 170, scale = c(1, 1), target = &quot;max&quot;) d3 &lt;- desirability(y3, 400, 600, target = 500) d1 par(mfrow = c(1, 2)) plot(d1, col = 2) plot(d3, col = 2) 5.6 Utilización de deseabilidades junto con experimentos diseñados La metodología de la deseabilidad se apoya en los objetos de diseño factorial. El resultado del método de deseabilidad puede almacenarse en el objeto de diseño, de modo que la información que pertenece a cada uno se almacena en el mismo lugar (es decir, el propio diseño). Experimento Los datos utilizados proceden de Derringer y Suich [1980]. Se definieron cuatro respuestas \\(y_1, y_2, y_3\\) e \\(y_4\\). Los factores utilizados en este experimento fueron la sílicio, el silano y el azufre con ajustes de factor alto de \\(1,7, 60, 2,8\\) y factores bajos de \\(0,7, 40, 1,8\\). Se desea maximizar \\(y_1\\) e \\(y_2\\) e \\(y_3\\) e \\(y_4\\) fijados en un objetivo específico. En primer lugar, se crea el diseño correspondiente y a continuación, utilizamos el método randomize para obtener el orden estándar del diseño. ddo &lt;- rsmDesign(k = 3, alpha = 1.633, cc = 0, cs = 6) ddo &lt;- randomize(ddo, so = TRUE) # Opcional names(ddo) &lt;- c(&quot;silica&quot;, &quot;silan&quot;, &quot;sulfur&quot;) # Opcional highs(ddo) &lt;- c(1.7, 60, 2.8) # Opcional lows(ddo) &lt;- c(0.7, 40, 1.8) # y1 &lt;- c(102, 120, 117, 198, 103, 132, 132, 139, 102, 154, 96, 163, 116, 153, 133, 133, 140, 142, 145, 142) y2 &lt;- c(900, 860, 800, 2294, 490, 1289, 1270, 1090, 770, 1690, 700, 1540, 2184, 1784, 1300, 1300, 1145, 1090, 1260, 1344) y3 &lt;- c(470, 410, 570, 240, 640, 270, 410, 380, 590, 260, 520, 380, 520, 290, 380, 380, 430, 430, 390, 390) y4 &lt;- c(67.5, 65, 77.5, 74.5, 62.5, 67, 78, 70, 76, 70, 63, 75, 65, 71, 70, 68.5, 68, 68, 69, 70) El data.frame ordenado de estas 4 respuestas se asigna al objeto de diseño ddo. response(ddo) &lt;- data.frame(y1, y2, y3, y4)[c(5, 2, 3, 8, 1, 6, 7, 4, 9:20), ] Las deseabilidades se incorporan con el método desires . Ya se han definido \\(y_1\\) e \\(y_3\\), por lo que quedan por definir las deseabilidades de \\(y_2\\) e \\(y_4\\). d2 &lt;- desirability(y2, 1000, 1300, target = &quot;max&quot;) d4 &lt;- desirability(y4, 60, 75, target = 67.5) Es necesario definir las deseabilidades con los nombres de las variables de respuesta para poder utilizarlas con el objeto de diseño. El método de los deseos se utiliza del siguiente modo desires(ddo) &lt;- d1 desires(ddo) &lt;- d2 desires(ddo) &lt;- d3 desires(ddo) &lt;- d4 Los ajustes se establecen como en Derringer y Suich [1980] utilizando los métodos de ajuste del paquete qualityTools de calidad. fits(ddo) &lt;- lm(y1 ~ A + B + C + A:B + A:C + B:C + I(A^2) + I(B^2) + I(C^2), data = ddo) fits(ddo) &lt;- lm(y2 ~ A + B + C + A:B + A:C + B:C + I(A^2) + I(B^2) + I(C^2), data = ddo) fits(ddo) &lt;- lm(y3 ~ A + B + C + A:B + A:C + B:C + I(A^2) + I(B^2) + I(C^2), data = ddo) fits(ddo) &lt;- lm(y4 ~ A + B + C + A:B + A:C + B:C + I(A^2) + I(B^2) + I(C^2), data = ddo) Finalmente se tiene que optimum(ddo, type = &quot;optim&quot;) ## Diseños de mezclas La generación de los diferentes tipos de diseños de mezcla es totalmente compatible incluyendo un contorno ternario y un gráfico 3D. El análisis de estos diseños debe realizarse sin ningún soporte específico mediante un método del paquete qualityTools. El método mixDesign puede utilizarse, por ejemplo, para crear diseños de celosía simplex y diseños de centroide simplex. Los métodos genéricos response, names, highs, lows, units y types vuelven a estar presentes. Un conjunto de datos Cornell [op. 2002] viene dado por el alargamiento del hilo para varias mezclas de tres factores. Este ejemplo puede reconstruirse utilizando el método mixDesign. #EJEMPLO mdo &lt;- mixDesign(3, 2, center = FALSE, axial = FALSE, randomize = FALSE, replicates = c(1, 1, 2, 3)) ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list embedding ## of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list embedding ## of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list embedding ## of S4 objects is deprecated names(mdo) &lt;- c(&quot;polyethylene&quot;, &quot;polystyrene&quot;, &quot;polypropylene&quot;) # Establecer respuesta (es decir, elongación del hilo) elongation &lt;- c(11.0, 12.4, 15.0, 14.8, 16.1, 17.7, 16.4, 16.6, 8.8, 10.0, 10.0, 9.7, 11.8, 16.8, 16.0) response(mdo) &lt;- elongation ## [1] &quot;elongation&quot; mdo ## StandOrder RunOrder Type A B C elongation ## 1 1 1 1-blend 1.0 0.0 0.0 11.0 ## 2 2 2 1-blend 1.0 0.0 0.0 12.4 ## 3 3 3 2-blend 0.5 0.5 0.0 15.0 ## 4 4 4 2-blend 0.5 0.5 0.0 14.8 ## 5 5 5 2-blend 0.5 0.5 0.0 16.1 ## 6 6 6 2-blend 0.5 0.0 0.5 17.7 ## 7 7 7 2-blend 0.5 0.0 0.5 16.4 ## 8 8 8 2-blend 0.5 0.0 0.5 16.6 ## 9 9 9 1-blend 0.0 1.0 0.0 8.8 ## 10 10 10 1-blend 0.0 1.0 0.0 10.0 ## 11 11 11 2-blend 0.0 0.5 0.5 10.0 ## 12 12 12 2-blend 0.0 0.5 0.5 9.7 ## 13 13 13 2-blend 0.0 0.5 0.5 11.8 ## 14 14 14 1-blend 0.0 0.0 1.0 16.8 ## 15 15 15 1-blend 0.0 0.0 1.0 16.0 par(mfrow = c(1, 2)) contourPlot3(A, B, C, elongation, data = mdo, form = &quot;quadratic&quot;) wirePlot3(A, B, C, elongation, data = mdo, form = &quot;quadratic&quot;, theta = -170) 5.7 Diseños Taguchi Los diseños Taguchi están disponibles utilizando el método taguchiDesign. Hay dos tipos de diseños taguchi: Nivel único: todos los factores tienen el mismo número de niveles (por ejemplo, dos niveles para un L4_2). Nivel mixto: los factores tienen diferentes números de niveles (por ejemplo, dos y tres niveles para un L18_2_3). Sin embargo, la mayoría de los diseños que se popularizaron como diseños Taguchi son factoriales fraccionados \\(2^k\\) con una resolución muy baja de III (es decir, los efectos principales se confunden con interacciones de dos factores) u otros diseños de nivel mixto. Se puede crear un diseño utilizando el método taguchiDesign. Los nombres de métodos genéricos, unidades, valores, resumen, trazado, lm y otros métodos se pueden utilizar. #EJEMPLO set.seed(1234) tdo &lt;- taguchiDesign(&quot;L9_3&quot;) ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;taguchiFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;taguchiFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;taguchiFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;taguchiFactor&quot;)): implicit list ## embedding of S4 objects is deprecated values(tdo) &lt;- list(A = c(20, 40, 60), B = c(&quot;material 1&quot;, &quot;material 2&quot;, &quot;material 3&quot;), C = c(1, 2, 3)) names(tdo) &lt;- c(&quot;Factor 1&quot;, &quot;Factor 2&quot;, &quot;Factor 3&quot;, &quot;Factor 4&quot;) summary(tdo) ## Taguchi SINGLE Design ## Information about the factors: ## ## A B C D ## value 1 20 material 1 1 1 ## value 2 40 material 2 2 2 ## value 3 60 material 3 3 3 ## name Factor 1 Factor 2 Factor 3 Factor 4 ## unit ## type numeric numeric numeric numeric ## ## ----------- ## ## StandOrder RunOrder Replicate A B C D y ## 1 4 1 1 2 1 2 3 NA ## 2 6 2 1 2 3 1 2 NA ## 3 9 3 1 3 3 2 1 NA ## 4 3 4 1 1 3 3 3 NA ## 5 2 5 1 1 2 2 2 NA ## 6 1 6 1 1 1 1 1 NA ## 7 7 7 1 3 1 3 2 NA ## 8 5 8 1 2 2 3 1 NA ## 9 8 9 1 3 2 1 3 NA ## ## ----------- El método response se utiliza para asignar los valores de las variables de respuesta. effectPlot puede utilizarse una vez más para visualizar los tamaños del efecto de los factores response(tdo) &lt;- rnorm(9) effectPlot(tdo, col = 2) Como extra es importante el uso del comando sessionInfo con el fin de obtener el número de versión de R y los paquetes cargados : sessionInfo() ## R version 4.3.1 (2023-06-16 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 11 x64 (build 22631) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=Spanish_Ecuador.utf8 LC_CTYPE=Spanish_Ecuador.utf8 ## [3] LC_MONETARY=Spanish_Ecuador.utf8 LC_NUMERIC=C ## [5] LC_TIME=Spanish_Ecuador.utf8 ## ## time zone: America/Guayaquil ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] qualityTools_1.55 MASS_7.3-60 ## [3] Rsolnp_1.16 tidyquant_1.0.7 ## [5] quantmod_0.4.25 TTR_0.24.3 ## [7] PerformanceAnalytics_2.0.4 xts_0.13.1 ## [9] zoo_1.8-12 lubridate_1.9.2 ## [11] forcats_1.0.0 stringr_1.5.0 ## [13] dplyr_1.1.2 purrr_1.0.2 ## [15] readr_2.1.4 tidyr_1.3.0 ## [17] tibble_3.2.1 ggplot2_3.4.4 ## [19] tidyverse_2.0.0 R6_2.5.1 ## [21] sloop_1.0.1 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.2.0 timeDate_4022.108 farver_2.1.1 ## [4] blob_1.2.4 fastmap_1.1.1 lazyeval_0.2.2 ## [7] digest_0.6.33 rpart_4.1.19 timechange_0.2.0 ## [10] lifecycle_1.0.3 survival_3.5-5 RSQLite_2.3.6 ## [13] magrittr_2.0.3 compiler_4.3.1 rlang_1.1.1 ## [16] sass_0.4.7 tools_4.3.1 utf8_1.2.3 ## [19] yaml_2.3.7 data.table_1.14.8 knitr_1.45 ## [22] labeling_0.4.2 bit_4.0.5 curl_5.0.2 ## [25] withr_2.5.0 nnet_7.3-19 grid_4.3.1 ## [28] fansi_1.0.4 timetk_2.9.0 colorspace_2.1-0 ## [31] future_1.33.0 globals_0.16.2 scales_1.2.1 ## [34] cli_3.6.1 rmarkdown_2.24 generics_0.1.3 ## [37] rstudioapi_0.15.0 future.apply_1.11.0 httr_1.4.7 ## [40] tzdb_0.4.0 DBI_1.2.2 cachem_1.0.8 ## [43] splines_4.3.1 parallel_4.3.1 vctrs_0.6.3 ## [46] hardhat_1.3.0 Matrix_1.6-5 jsonlite_1.8.7 ## [49] bookdown_0.38 hms_1.1.3 bit64_4.0.5 ## [52] listenv_0.9.0 gower_1.0.1 jquerylib_0.1.4 ## [55] recipes_1.0.7 glue_1.6.2 parallelly_1.36.0 ## [58] codetools_0.2-19 Quandl_2.11.0 rsample_1.2.1 ## [61] stringi_1.7.12 gtable_0.3.4 quadprog_1.5-8 ## [64] munsell_0.5.0 furrr_0.3.1 pillar_1.9.0 ## [67] htmltools_0.5.6 ipred_0.9-14 truncnorm_1.0-9 ## [70] lava_1.7.2.1 evaluate_0.21 lattice_0.21-8 ## [73] highr_0.10 memoise_2.0.1 bslib_0.5.1 ## [76] class_7.3-22 Rcpp_1.0.11 nlme_3.1-162 ## [79] prodlim_2023.03.31 mgcv_1.8-42 xfun_0.40 ## [82] pkgconfig_2.0.3 "],["cambio-de-funciones.html", "Capítulo 6 Cambio de Funciones 6.1 Fase 1: Definir 6.2 Fase 2: Medir", " Capítulo 6 Cambio de Funciones .scroll-100 { max-height: 100px; overflow-y: auto; background-color: inherit; } library(qualityTools) library(tidyverse) # Paquetes necesarios # install.packages(&quot;ggplot2&quot;) # install.packages(&quot;patchwork&quot;) # install.packages(&quot;gridExtra&quot;) library(ggplot2) library(patchwork) library(gridExtra) 6.1 Fase 1: Definir 6.1.1 1. Función Pareto # Nueva Función (se quita argumento `las`) ParetoChart_ &lt;- function (x, weight, showTable = TRUE, showPlot = TRUE, main, col, border, xlab, ylab = &quot;Frequency&quot;, percentVec, ...) { varName = deparse(substitute(x))[1] corp.col = &quot;#C4B9FF&quot; corp.border = &quot;#9E0138&quot; if (!is.vector(x) &amp; !is.data.frame(x) &amp; !is.table(x)) stop(&quot;x should be a vector, dataframe or a table&quot;) if (is.table(x)) { xtable = x } if (is.vector(x)) { if (!is.null(names(x))) xtable = as.table(x) else xtable = table(x) } if (!missing(weight)) { if (!is.numeric(weight)) stop(&quot;weight must be numeric!&quot;) if (is.null(names(weight))) stop(&quot;weight is missing names for matching!&quot;) else { if (FALSE %in% (sort(names(weight)) == sort(names(xtable)))) stop(&quot;names of weight and table do not match!&quot;) else { for (i in 1:length(xtable)) { xtable[i] = weight[names(weight) == names(xtable)[i]] * xtable[i] } } } } else { weight = FALSE } if (missing(showTable)) showTable = TRUE if (missing(xlab)) xlab = &quot;&quot; if (missing(main)) main = paste(&quot;Pareto Chart for&quot;, varName) if (missing(col)) col = corp.col if (missing(border)) border = corp.border if (missing(percentVec)) percentVec = seq(0, 1, by = 0.25) call &lt;- match.call(expand.dots = TRUE) # Plot if (length(xtable) &gt; 1) { ylim = c(min(xtable), max(xtable) * 1.025) xtable = c(sort(xtable, decreasing = TRUE, na.last = TRUE)) cumFreq = cumsum(xtable) sumFreq = sum(xtable) percentage = xtable/sum(xtable) * 100 cumPerc = cumFreq/sumFreq * 100 data &lt;- data.frame(Frequency = xtable, Cum.Frequency = cumFreq, Percentage = round(percentage, digits = 2), Cum.Percentage = round(cumPerc, digits = 2)) tabla &lt;- t(data) p &lt;- ggplot(data, aes(x = reorder(names(xtable), -xtable), y = Frequency)) + geom_col(aes(fill = &quot;Frequency&quot;), width = 0.7) + geom_point(aes(y = Cum.Frequency, color = &quot;Cumulative Percentage&quot;), size = 3) + geom_line(aes(y = Cum.Frequency, group = 1, color = &quot;Cumulative Percentage&quot;), line = 0.5) + scale_y_continuous(name = ylab, sec.axis = sec_axis(~ . / sum(xtable), name = &quot;Cumulative Percentage&quot;, labels = percentVec)) + scale_x_discrete(name = xlab) + scale_color_manual(values = c(border, border)) + scale_fill_manual(values = col) + theme(legend.position = &quot;none&quot;) + labs(title = main)+ theme_minimal() + theme(plot.title = element_text(hjust = 0.5,face = &quot;bold&quot;)) } else { warning(&quot;data should have at least two categories!&quot;) } if(showPlot == TRUE){ if(showTable == TRUE){ show(p/tableGrob(tabla)) } else { show(p) } } else{ show(tabla) } } Resultados antes: defectos &lt;-c(rep(&quot;E&quot;,62),rep(&quot;B&quot;,15),rep(&quot;F&quot;,3),rep(&quot;A&quot;,10),rep(&quot;C&quot;,20),rep(&quot;D&quot;,10)) paretoChart(defectos) ## ## Frequency 62 20 15 10 10 3 ## Cum. Frequency 62 82 97 107 117 120 ## Percentage 51.7% 16.7% 12.5% 8.3% 8.3% 2.5% ## Cum. Percentage 51.7% 68.3% 80.8% 89.2% 97.5% 100.0% ## ## Frequency 62.00000 20.00000 15.00000 10.000000 10.000000 3.0 ## Cum. Frequency 62.00000 82.00000 97.00000 107.000000 117.000000 120.0 ## Percentage 51.66667 16.66667 12.50000 8.333333 8.333333 2.5 ## Cum. Percentage 51.66667 68.33333 80.83333 89.166667 97.500000 100.0 Resultados ahora: ParetoChart_(defectos) ## Warning in geom_line(aes(y = Cum.Frequency, group = 1, color = &quot;Cumulative ## Percentage&quot;), : Ignoring unknown parameters: `line` Podemos utilizar parámetros para mostrar la tabla o la gráfica: # Mostrar solo la gráfica ParetoChart_(defectos, showTable = FALSE) ## Warning in geom_line(aes(y = Cum.Frequency, group = 1, color = &quot;Cumulative ## Percentage&quot;), : Ignoring unknown parameters: `line` # Mostrar solo la tabla ParetoChart_(defectos, showPlot = FALSE) ## Warning in geom_line(aes(y = Cum.Frequency, group = 1, color = &quot;Cumulative ## Percentage&quot;), : Ignoring unknown parameters: `line` ## E C B A D F ## Frequency 62.00 20.00 15.00 10.00 10.00 3.0 ## Cum.Frequency 62.00 82.00 97.00 107.00 117.00 120.0 ## Percentage 51.67 16.67 12.50 8.33 8.33 2.5 ## Cum.Percentage 51.67 68.33 80.83 89.17 97.50 100.0 Podemos cambiar los colores de los puntos y las barras: ParetoChart_(defectos, col=&#39;blue&#39;, border=&#39;green&#39;) ## Warning in geom_line(aes(y = Cum.Frequency, group = 1, color = &quot;Cumulative ## Percentage&quot;), : Ignoring unknown parameters: `line` 6.2 Fase 2: Medir 6.2.1 1. Función cg Para poder implementar esta función, primero debemos modificar 3 funciones que se utilizan en esta función macro. Además utilizaremos los siguientes datos de pruebas: x &lt;- c(9.991, 10.013, 10.001, 10.007, 10.010, 10.013, 10.008, 10.017, 10.005, 10.005, 10.002, 10.017, 10.005, 10.002, 9.996, 10.011, 10.009, 10.006, 10.008, 10.003, 10.002, 10.006, 10.010, 9.992, 10.013) target = 10.003 tolerance = c(9.903, 10.103) ref.interval = pnorm(3) - pnorm(-3) facCg = 0.2 facCgk = 0.1 n = 0.2 type = &quot;b&quot; col = &quot;black&quot; pch = 19 #xlim = NULL #ylim = NULL conf.level = 0.95 cex.val = 1.5 sd = sd(x) mean = mean(x) ref.ar = qnorm(ref.interval, mean, sd) - qnorm(1 - ref.interval, mean, sd) quant1 = qnorm((1 - ref.interval)/2, mean, sd) quant2 = qnorm(ref.interval + (1 - ref.interval)/2, mean, sd) xlim = c(0, length(x)) ylim = c(min(x, target - n/2 * (abs(diff(tolerance))), quant1, quant2), max(x, target + n/2 * (abs(diff(tolerance))), quant1, quant2)) 6.2.1.1 CgRunChart cg_RunChart &lt;- function (x, target, tolerance, ref.interval, facCg, facCgk, n = 0.2, type = &quot;b&quot;, col = &quot;black&quot;, pch = 19, xlim = NULL, ylim = NULL, main = &quot;Run Chart&quot;, conf.level = 0.95, cgOut = TRUE) { if (missing(x)) { stop(&quot;x must be given as a vector&quot;) } if (missing(target)) { target &lt;- mean(x) targetmissing &lt;- FALSE } else { targetmissing &lt;- TRUE } if (missing(ref.interval)) { ref.interval &lt;- qnorm(0.99865) - qnorm(0.00135) } sd &lt;- sd(x) mean &lt;- mean(x) ref.ar &lt;- qnorm(ref.interval, mean, sd) - qnorm(1 - ref.interval, mean, sd) if (missing(facCg)) { facCg &lt;- 0.2 } if (missing(facCgk)) { facCgk &lt;- 0.1 } if (missing(tolerance)) { width &lt;- ref.ar/facCg tolerance &lt;- numeric(2) tolerance[1] &lt;- mean - width/2 tolerance[2] &lt;- mean + width/2 } quant1 &lt;- qnorm((1 - ref.interval)/2, mean, sd) quant2 &lt;- qnorm(ref.interval + (1 - ref.interval)/2, mean, sd) if (length(tolerance) != 2) { stop(&quot;tolerance has wrong length&quot;) } if (missing(xlim)) { xlim &lt;- c(0, length(x)) } if (missing(ylim)) { ylim &lt;- c(min(x, target - n/2 * (abs(diff(tolerance))), quant1, quant2), max(x, target + n/2 * (abs(diff(tolerance))), quant1, quant2)) } if (missing(main)) { main &lt;- &quot;Run Chart&quot; } Cg &lt;- (facCg * tolerance[2]-tolerance[1])/ref.interval Cgk &lt;- (facCgk * abs(target-mean(x))/(ref.interval/2)) # Create a data frame for plotting df &lt;- data.frame(x = x, y = x) # Add target line df$y_target &lt;- target # Calculate the upper and lower control limits df$y_lower &lt;- quant1 df$y_upper &lt;- quant2 # Calculate the tolerance limits df$y_tolerance_lower &lt;- tolerance[1] df$y_tolerance_upper &lt;- tolerance[2] # Calculate the mean df$y_mean &lt;- mean # Calculate the Cg and Cgk values df$Cg &lt;- Cg df$Cgk &lt;- Cgk # Create the ggplot # 1. Principal plot and target line p &lt;- ggplot(df, aes(x = seq_along(x), y = x)) + geom_point(color = col, shape = pch) + geom_line(color = col, linetype = &quot;solid&quot;) + scale_x_continuous(limits = c(xlim[1] - 0.05 * xlim[2], xlim[2]), expand = c(0, 0)) + labs(title = main, x = &quot;Index&quot;, y = &quot;x&quot;) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5,face = &quot;bold&quot;))+ geom_hline(aes(yintercept = target)) # Linea target # 2. Red Plot (Lowess) p &lt;- p + geom_smooth(method = &quot;loess&quot;, color = &quot;red&quot;, se = FALSE, span = 1.25, size = 0.25,) # 3. Green lines p &lt;- p + geom_hline(aes(yintercept = mean), linetype = &quot;dashed&quot;, color = &quot;seagreen&quot;)+ #center line geom_hline(aes(yintercept = quant1), linetype = &quot;dashed&quot;, color = &quot;seagreen&quot;) + # Bottom line geom_hline(aes(yintercept = quant2), linetype = &quot;dashed&quot;, color = &quot;seagreen&quot;) # Top line # 4. Xtar +- 0.1 p &lt;- p + geom_hline(yintercept = c(target + n/2 * (abs(diff(tolerance))), target - n/2 * (abs(diff(tolerance)))), color = &quot;#012B78&quot;, linetype = &quot;solid&quot;) # Agregar líneas #Label p &lt;- p + scale_y_continuous(limits = ylim, expand = c(0, 0),sec.axis = sec_axis(~ .,breaks = c(target,mean,quant1,quant2,target + n/2 * (abs(diff(tolerance))), target - n/2 * (abs(diff(tolerance)))), labels=c(&quot;target&quot;,expression(bar(x)),substitute(x[a * b], list(a = round(((1 - ref.interval)/2) * 100, 3), b = &quot;%&quot;)), substitute(x[a * b], list(a = round(((ref.interval + (1 - ref.interval)/2)) * 100, 3), b = &quot;%&quot;)),substitute(x[tar] + a, list(a = round(n/2, 4))),substitute(x[tar] - a, list(a = round(n/2, 4))))))+ theme(axis.text.y.right = element_text(size = 15)) # Label Cg and Cgk if (cgOut == TRUE) { p &lt;- p + annotation_custom( grob = grid::textGrob( label = c(paste(&quot;Cg: &quot;, round(Cg,digits = 6))), x = unit(1, &quot;npc&quot;) - unit(0.15, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.05, &quot;cm&quot;), just = c(&quot;right&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 12, fontface = &quot;bold&quot;) ) ) + annotation_custom( grob = grid::textGrob( label = c(paste(&quot;Cgk:&quot;, round(Cgk,digits = 6))), x = unit(1, &quot;npc&quot;) - unit(0.15, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.6, &quot;cm&quot;), just = c(&quot;right&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 12, fontface = &quot;bold&quot;) ) ) suppressMessages(show(p)) } else{ suppressMessages(show(p)) } invisible(list(Cg, Cgk)) } Resultados antes: cgRunChart(x = x, target = target, tolerance = tolerance, ref.interval = ref.interval, facCg = facCg, facCgk = facCgk, n = n, type = type, col = col, pch = pch, xlim = xlim, ylim = ylim, main = &quot;Run Chart&quot;, conf.level = conf.level, cgOut = FALSE) Resultados Ahora: cg_RunChart(x = x, target = target, tolerance = tolerance, ref.interval = ref.interval, facCg = facCg, facCgk = facCgk, n = n, type = type, col = col, pch = pch, xlim = xlim, ylim = ylim, main = &quot;Run Chart&quot;, conf.level = conf.level, cgOut = FALSE) 6.2.1.2 cgHist # Nueva función cg_HistChart &lt;- function (x, target, tolerance, ref.interval, facCg, facCgk, n = 0.2, col, xlim, ylim, main, conf.level = 0.95, cgOut = TRUE) { if (missing(x)) stop(&quot;x must be given as a vector&quot;) if (missing(target)) { target = mean(x) targetmissing = FALSE } else targetmissing = TRUE if (missing(ref.interval)) ref.interval = pnorm(3) - pnorm(-3) sd = sd(x) mean = mean(x) ref.ar = qnorm(ref.interval, mean, sd) - qnorm(1 - ref.interval, mean, sd) if (missing(facCg)) facCg = 0.2 if (missing(facCgk)) facCgk = 0.1 if (missing(tolerance)) warning(&quot;Missing tolerance! The specification limits are choosen to get Cg = 1&quot;) if (missing(tolerance)) { width = ref.ar/facCg tolerance = numeric(2) tolerance[1] = mean(x) - width/2 tolerance[2] = mean(x) + width/2 } quant1 = qnorm((1 - ref.interval)/2, mean, sd) quant2 = qnorm(ref.interval + (1 - ref.interval)/2, mean, sd) if (length(tolerance) != 2) stop(&quot;tolerance has wrong length&quot;) if (missing(col)) col = &quot;lightblue&quot; if (missing(xlim)) xlim = c(0, length(x)) if (missing(ylim)) ylim = c(min(x, target - n/2 * (abs(diff(tolerance))), quant1, quant2), max(x, target + n/2 * (abs(diff(tolerance))), quant1, quant2)) if (missing(main)) main = paste(&quot;Histogram of&quot;, deparse(substitute(x)), &quot;- target&quot;) Cg &lt;- (facCg * tolerance[2]-tolerance[1])/ref.interval Cgk &lt;- (facCgk * abs(target-mean(x))/(ref.interval/2)) # Calculos previos x.c &lt;- x - target temp &lt;- hist(x.c, plot = FALSE) # Obtenemos la información para el histograma df &lt;- data.frame( mid = temp$mids, density = temp$density ) width &lt;- diff(df$mid)[1] # Ancho de cada barra # Histograma p &lt;- ggplot(df, aes(x = mid, y = density)) + geom_bar(stat = &quot;identity&quot;, width = width, fill = &quot;lightblue&quot;, color = &quot;black&quot;, alpha = 0.5) + labs(y = &quot;Density&quot;, x = &quot;x.c&quot;, title = main) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5,face = &quot;bold&quot;))+ guides(color = guide_legend(title.position = &quot;top&quot;, title.hjust = 0.5)) # Linea x=0 p &lt;- p + geom_vline(xintercept = 0, color = &quot;red&quot;) # Intervalos de Confianza - Azules test = t.test(x.c, mu = 0, conf.level = conf.level) p &lt;- p + geom_vline(aes(xintercept = test$conf.int[1], color = &quot;Confidence interval&quot;), linetype = &quot;dashed&quot;, col = &quot;blue&quot;) + geom_vline(aes(xintercept = test$conf.int[2], color = &quot;Confidence interval&quot;), linetype = &quot;dashed&quot;, col = &quot;blue&quot;) + theme(legend.position = &quot;none&quot;) # Curva de densidad p &lt;- p + geom_line(data = data.frame(x = density(x.c)$x, y = density(x.c)$y), aes(x = x, y = y), color = &quot;black&quot;, linewidth = 0.5) # Hipotesis, P_val y t_val p &lt;- p + annotation_custom(grob = grid::textGrob(label = c(expression(paste(H[0], &quot; : Bias = 0&quot;))), x = unit(0.05, &quot;npc&quot;) + unit(0.05, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.05, &quot;cm&quot;), just = c(&quot;left&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 12, fontface = &quot;bold&quot;) ) ) + annotation_custom( grob = grid::textGrob( label = c(paste(&quot;t-value: &quot;, round(test$statistic, 3))), x = unit(0.05, &quot;npc&quot;) + unit(0.05, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.5, &quot;cm&quot;), just = c(&quot;left&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 11) ) ) + annotation_custom(grob = grid::textGrob(label = c(paste(&quot;p-value: &quot;, round(test$p.value, 3))), x = unit(0.05, &quot;npc&quot;) + unit(0.05, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.85, &quot;cm&quot;), just = c(&quot;left&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 11) ) ) # Añadir label del Cg y Cgk if (cgOut == TRUE) { p &lt;- p + annotation_custom( grob = grid::textGrob( label = c(paste(&quot;Cg: &quot;, round(Cg,digits = 6))), x = unit(1, &quot;npc&quot;) - unit(0.15, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.05, &quot;cm&quot;), just = c(&quot;right&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 12) ) ) + annotation_custom( grob = grid::textGrob( label = c(paste(&quot;Cgk:&quot;, round(Cgk,digits = 6))), x = unit(1, &quot;npc&quot;) - unit(0.15, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.6, &quot;cm&quot;), just = c(&quot;right&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 12) ) ) show(p) } else{ p &lt;- p + annotation_custom( grob = grid::textGrob( label = c(paste(&quot;---- conf. int&quot;)), x = unit(1, &quot;npc&quot;) - unit(0.15, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.05, &quot;cm&quot;), just = c(&quot;right&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 12) ) ) show(p) } invisible(list(Cg, Cgk)) } Resultados Anteriores: cgHist(x = x, target = target, tolerance = tolerance, ref.interval = ref.interval, facCg = facCg, facCgk = facCgk, n = n, col = &quot;lightblue&quot;, xlim = xlim, ylim = ylim, main = paste(&quot;Histogram of&quot;, deparse(substitute(x)), &quot;- target&quot;), conf.level = conf.level, cgOut = FALSE) Resultados Ahora: cg_HistChart(x = x, target = target, tolerance = tolerance, ref.interval = ref.interval, facCg = facCg, facCgk = facCgk, n = n, col = &quot;lightblue&quot;, xlim = xlim, ylim = ylim, main = paste(&quot;Histogram of&quot;, deparse(substitute(x)), &quot;- target&quot;), conf.level = conf.level, cgOut = FALSE) 6.2.1.3 cgToleranceView # Nueva Función cg_ToleranceChart &lt;- function (x, target, tolerance, ref.interval, facCg, facCgk, n = 0.2, type, col, pch, xlim, ylim, main, conf.level = 0.95, cgOut = TRUE) { if (missing(x)) stop(&quot;x must be given as a vector&quot;) if (missing(target)) { target = mean(x) targetmissing = FALSE } else targetmissing = TRUE if (missing(ref.interval)) ref.interval = pnorm(3) - pnorm(-3) sd = sd(x) mean = mean(x) ref.ar = qnorm(ref.interval, mean, sd) - qnorm(1 - ref.interval, mean, sd) if (missing(facCg)) facCg = 0.2 if (missing(facCgk)) facCgk = 0.1 if (missing(tolerance)) warning(&quot;Missing tolerance! The specification limits are choosen to get Cg = 1&quot;) if (missing(tolerance)) { width = ref.ar/facCg tolerance = numeric(2) tolerance[1] = mean(x) - width/2 tolerance[2] = mean(x) + width/2 } quant1 = qnorm((1 - ref.interval)/2, mean, sd) quant2 = qnorm(ref.interval + (1 - ref.interval)/2, mean, sd) if (length(tolerance) != 2) stop(&quot;tolerance has wrong length&quot;) if (missing(type)) type = &quot;b&quot; if (missing(col)) col = 1 if (missing(pch)) pch = 19 if (missing(xlim)) xlim = c(0, length(x)) if (missing(ylim)) ylim = c(min(x, target - n/2 * (abs(diff(tolerance))), quant1, quant2), max(x, target + n/2 * (abs(diff(tolerance))), quant1, quant2)) if (missing(main)) main = &quot;Tolerance View&quot; Cg &lt;- (facCg * tolerance[2]-tolerance[1])/ref.interval Cgk &lt;- (facCgk * abs(target-mean(x))/(ref.interval/2)) # Gráfica p &lt;- ggplot(data.frame(x = 1:length(x), y = x), aes(x = x, y = y)) + geom_point(color = col, shape = pch) + geom_line(color = col, linetype = &quot;solid&quot;)+ geom_hline(aes(yintercept = target), linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_hline(aes(yintercept = tolerance[1]), linetype = &quot;dashed&quot;, color = &quot;blue&quot;) + geom_hline(aes(yintercept = tolerance[2]), linetype = &quot;dashed&quot;, color = &quot;blue&quot;) + geom_hline(aes(yintercept = (target + n/2 * (tolerance[2] - tolerance[1]))), color = &quot;black&quot;) + geom_hline(aes(yintercept = (target - n/2 * (tolerance[2] - tolerance[1]))), color = &quot;black&quot;) + scale_color_manual(values = c(&quot;Data&quot; = col)) + labs(x = &quot;&quot;, y = &quot;x&quot;, color = &quot;Variable&quot;, title = main)+ theme_minimal()+theme(plot.title = element_text(hjust = 0.5,face = &quot;bold&quot;))+ theme(legend.position = &quot;none&quot;) if (cgOut == TRUE) { p &lt;- p + annotation_custom( grob = grid::textGrob( label = c(paste(&quot;Cg: &quot;, round(Cg,digits = 6))), x = unit(1, &quot;npc&quot;) - unit(0.15, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.05, &quot;cm&quot;), just = c(&quot;right&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 12, fontface = &quot;bold&quot;) ) ) + annotation_custom( grob = grid::textGrob( label = c(paste(&quot;Cgk:&quot;, round(Cgk,digits = 6))), x = unit(1, &quot;npc&quot;) - unit(0.15, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.6, &quot;cm&quot;), just = c(&quot;right&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 12, fontface = &quot;bold&quot;) ) ) show(p) } else{ show(p) } invisible(list(Cg, Cgk)) } Resultados Antes: cgToleranceView(x = x, target = target, tolerance = tolerance, ref.interval = ref.interval, facCg = facCg, facCgk = facCgk, n = n, type = type, col = col, pch = pch, xlim = xlim, ylim = ylim, main = &quot;Tolerance View&quot;, conf.level = conf.level, cgOut = TRUE) Resultados Ahora: cg_ToleranceChart(x = x, target = target, tolerance = tolerance, ref.interval = ref.interval, facCg = facCg, facCgk = facCgk, n = n, type = type, col = col, pch = pch, xlim = xlim, ylim = ylim, main = &quot;Tolerance View&quot;, conf.level = conf.level, cgOut = TRUE) 6.2.1.4 Funcion cg Ahora la función cg se modificará de la siguiente forma: # Funcion Nueva cg_ &lt;- function (x, target, tolerance, ref.interval, facCg, facCgk, n = 0.2, type, col, pch, xlim, ylim, conf.level = 0.95, cex.val = 1.5) { old.par &lt;- par(no.readonly = TRUE) if (missing(x)) stop(&quot;x must be given as a vector&quot;) if (missing(target)) { target = mean(x) targetmissing = FALSE } else targetmissing = TRUE if (missing(ref.interval)) ref.interval = pnorm(3) - pnorm(-3) sd = sd(x) mean = mean(x) ref.ar = qnorm(ref.interval, mean, sd) - qnorm(1 - ref.interval, mean, sd) if (missing(facCg)) facCg = 0.2 if (missing(facCgk)) facCgk = 0.1 if (missing(tolerance)) warning(&quot;Missing tolerance! The specification limits are choosen to get Cg = 1&quot;) if (missing(tolerance)) { width = ref.ar / facCg tolerance = numeric(2) tolerance[1] = mean(x) - width / 2 tolerance[2] = mean(x) + width / 2 } quant1 = qnorm((1 - ref.interval) / 2, mean, sd) quant2 = qnorm(ref.interval + (1 - ref.interval) / 2, mean, sd) if (length(tolerance) != 2) stop(&quot;tolerance has wrong length&quot;) if (missing(type)) type = &quot;b&quot; if (missing(col)) col = 1 if (missing(pch)) pch = 19 if (missing(xlim)) xlim = c(0, length(x)) if (missing(ylim)) ylim = c(min(x, target - n / 2 * (abs(diff( tolerance ))), quant1, quant2), max(x, target + n / 2 * (abs(diff( tolerance ))), quant1, quant2)) Cg &lt;- (facCg * tolerance[2] - tolerance[1]) / ref.interval Cgk &lt;- (facCgk * abs(target - mean(x)) / (ref.interval / 2)) # Plots # RunChart df1 &lt;- data.frame(x = x, y = x) df1$y_target &lt;- target df1$y_lower &lt;- quant1 df1$y_upper &lt;- quant2 df1$y_tolerance_lower &lt;- tolerance[1] df1$y_tolerance_upper &lt;- tolerance[2] df1$y_mean &lt;- mean df1$Cg &lt;- Cg df1$Cgk &lt;- Cgk p1 &lt;- ggplot(df1, aes(x = seq_along(x), y = x)) + geom_point(color = col, shape = pch) + geom_line(color = col, linetype = &quot;solid&quot;) + scale_x_continuous(limits = c(xlim[1] - 0.05 * xlim[2], xlim[2]), expand = c(0, 0)) + labs(title = &quot;Run Chart&quot;, x = &quot;Index&quot;, y = &quot;x&quot;) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;)) + geom_hline(aes(yintercept = target)) + geom_smooth( method = &quot;loess&quot;, color = &quot;red&quot;, se = FALSE, span = 1.25, size = 0.25 ) + geom_hline(aes(yintercept = mean), linetype = &quot;dashed&quot;, color = &quot;seagreen&quot;) + #center line geom_hline(aes(yintercept = quant1), linetype = &quot;dashed&quot;, color = &quot;seagreen&quot;) + # Bottom line geom_hline(aes(yintercept = quant2), linetype = &quot;dashed&quot;, color = &quot;seagreen&quot;) + geom_hline( yintercept = c(target + n / 2 * (abs(diff( tolerance ))), target - n / 2 * (abs(diff( tolerance )))), color = &quot;#012B78&quot;, linetype = &quot;solid&quot; ) + scale_y_continuous( limits = ylim, expand = c(0, 0), sec.axis = sec_axis( ~ ., breaks = c( target, mean, quant1, quant2, target + n / 2 * (abs(diff(tolerance))), target - n / 2 * (abs(diff(tolerance))) ), labels = c( &quot;target&quot;, expression(bar(x)), substitute(x[a * b], list(a = round(((1 - ref.interval) / 2 ) * 100, 3), b = &quot;%&quot;)), substitute(x[a * b], list(a = round(((ref.interval + (1 - ref.interval) / 2) ) * 100, 3), b = &quot;%&quot;)), substitute(x[tar] + a, list(a = round(n / 2, 4))), substitute(x[tar] - a, list(a = round(n / 2, 4))) ) ) ) + theme(axis.text.y.right = element_text(size = 15)) # HistChart x.c &lt;- x - target temp &lt;- hist(x.c, plot = FALSE) df3 &lt;- data.frame(mid = temp$mids, density = temp$density) width &lt;- diff(df3$mid)[1] # Ancho de cada barra p3 &lt;- ggplot(df3, aes(x = mid, y = density)) + geom_bar( stat = &quot;identity&quot;, width = width, fill = &quot;lightblue&quot;, color = &quot;black&quot;, alpha = 0.5 ) + labs(y = &quot;Density&quot;, x = &quot;x.c&quot;, title = paste(&quot;Histogram of&quot;,deparse(substitute(x)),&quot;- target&quot;)) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;)) + guides(color = guide_legend(title.position = &quot;top&quot;, title.hjust = 0.5)) + geom_vline(xintercept = 0, color = &quot;red&quot;) test = t.test(x.c, mu = 0, conf.level = conf.level) p3 &lt;- p3 + geom_vline( aes(xintercept = test$conf.int[1], color = &quot;Confidence interval&quot;), linetype = &quot;dashed&quot;, col = &quot;blue&quot; ) + geom_vline( aes(xintercept = test$conf.int[2], color = &quot;Confidence interval&quot;), linetype = &quot;dashed&quot;, col = &quot;blue&quot; ) + theme(legend.position = &quot;none&quot;) + geom_line( data = data.frame(x = density(x.c)$x, y = density(x.c)$y), aes(x = x, y = y), color = &quot;black&quot;, linewidth = 0.5 ) p3 &lt;- p3 + annotation_custom(grob = grid::textGrob( label = c(expression(paste(H[0], &quot; : Bias = 0&quot;))), x = unit(0.05, &quot;npc&quot;) + unit(0.05, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.05, &quot;cm&quot;), just = c(&quot;left&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 12, fontface = &quot;bold&quot;) )) + annotation_custom(grob = grid::textGrob( label = c(paste(&quot;t-value: &quot;, round(test$statistic, 3))), x = unit(0.05, &quot;npc&quot;) + unit(0.05, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.5, &quot;cm&quot;), just = c(&quot;left&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 11) )) + annotation_custom(grob = grid::textGrob( label = c(paste(&quot;p-value: &quot;, round(test$p.value, 3))), x = unit(0.05, &quot;npc&quot;) + unit(0.05, &quot;cm&quot;), y = unit(1, &quot;npc&quot;) - unit(0.85, &quot;cm&quot;), just = c(&quot;left&quot;, &quot;top&quot;), gp = grid::gpar(fontsize = 11) )) # Tolerance View p4 &lt;- ggplot(data.frame(x = 1:length(x), y = x), aes(x = x, y = y)) + geom_point(color = col, shape = pch) + geom_line(color = col, linetype = &quot;solid&quot;) + geom_hline(aes(yintercept = target), linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_hline(aes(yintercept = tolerance[1]), linetype = &quot;dashed&quot;, color = &quot;blue&quot;) + geom_hline(aes(yintercept = tolerance[2]), linetype = &quot;dashed&quot;, color = &quot;blue&quot;) + geom_hline(aes(yintercept = (target + n / 2 * ( tolerance[2] - tolerance[1] ))), color = &quot;black&quot;) + geom_hline(aes(yintercept = (target - n / 2 * ( tolerance[2] - tolerance[1] ))), color = &quot;black&quot;) + scale_color_manual(values = c(&quot;Data&quot; = col)) + labs( x = &quot;&quot;, y = &quot;x&quot;, color = &quot;Variable&quot;, title = &quot;Tolerance View&quot; ) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;)) + theme(legend.position = &quot;none&quot;) # Data Box p2 &lt;- ggplot(data = data.frame(x = 0, y = 0), aes(x, y)) + theme_bw() + annotate( &#39;text&#39;, x = 0.25, y = 0.40, label = paste(&quot;bar(x)==&quot;, round(mean, 2)), parse = TRUE, size = 3, hjust = 0 ) + annotate( &#39;text&#39;, x = 0.25, y = 0.35, label = paste(&quot;s==&quot;, round(sd, 2)), parse = TRUE, size = 3, hjust = 0 ) + annotate( &#39;text&#39;, x = 0.25, y = 0.3, label = paste(&quot;target==&quot;, round(target, 5)), parse = TRUE, size = 3, hjust = 0 ) + annotate( &#39;text&#39;, x = 0.25, y = 0.25, label = paste(&quot;C[g]==&quot;, round(Cg, 2)), parse = TRUE, size = 3, hjust = 0 ) + annotate( &#39;text&#39;, x = 0.25, y = 0.20, label = paste(&quot;C[gk]==&quot;, round(Cgk, 2)), parse = TRUE, size = 3, hjust = 0 ) + theme( axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank() ) + xlim(c(0.15, 0.5)) + ylim(c(0.1, 0.5)) design &lt;- &quot; 112 113 114 &quot; p &lt;- p1 + p2 + p3 + p4 + plot_layout(design = design) suppressMessages(show(p)) invisible(list(Cg, Cgk)) } Resultados Antes: x &lt;- c ( 9.991, 10.013, 10.001, 10.007, 10.010, 10.013, 10.008, 10.017, 10.005, 10.005, 10.002, 10.017, 10.005, 10.002, 9.996, 10.011, 10.009 , 10.006, 10.008, 10.003, 10.002, 10.006, 10.010, 9.992, 10.013) cg(x, target = 10.003, tolerance = c(9.903, 10.103)) Resultados Ahora: cg_(x, target = 10.003, tolerance = c(9.903, 10.103)) "],["referencias.html", "Referencias", " Referencias Wickham, H. (2019). Advanced r. chapman and hall/CRC. Chang W (2022). R6: Encapsulated Classes with Reference Semantics. Dancho, M (2023). R Quantitative Analysis Package Integrations in tidyquant. Roth, T. (2016). Working with the qualityTools package. Six Sigma Daily (2012). What is DMAIC?. "]]
