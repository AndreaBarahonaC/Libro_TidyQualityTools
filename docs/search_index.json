[["qualitytools.html", "Capítulo 5 QualityTools 5.1 Fase 1: Definir 5.2 Fase 2: Medir 5.3 Fase 3: Analizar 5.4 Fase 4: Mejorar 5.5 Deseabilidades 5.6 Utilización de deseabilidades junto con experimentos diseñados 5.7 Diseños Taguchi", " Capítulo 5 QualityTools Este trabajo pretende dar una breve introducción a los métodos del paquete QualityTools. Este paquete se implementó con fines didácticos para servir como una “Caja de Herramientas” (Six-Sigma) y contiene métodos asociados con el ciclo de resolución con la metodología de: “Definir, Medir, Analizar, Mejorar y Controlar” (con sus siglas en inglés DMAIC). El uso de estos métodos se ilustran con ayuda de conjuntos de datos creados artificalmente, a continuación se explica, el objetivo de cada una de las fases de este ciclo: Definir: Describir el problema y sus consecuencias (financieras), es la etapa fundamental para delimitar el problema. Los diagramas de flujo. Los diagramas de flujo de procesos identifican elementos cruciales del proceso (es decir, actividades), las técnicas de creatividad como Brainwriting y Brainstorming, así como la técnica SIPOC4, deberían conducir, dependiendo del tamaño futuro del proyecto, a posiblemente una carta del proyecto. Medir: Elaborar un plan razonable para recopilar los datos requeridos y asegurarse de que los sistemas de medición sean capaces (es decir, ningún sesgo o sesgo conocido y la menor variación inmanente del sistema que contribuya a las mediciones como sea posible). Dentro de esta fase se proporciona una descripción de la situación con la ayuda de índices de capacidad de proceso o de medición (MSA5 Tipo I) o un Gage R&amp;R (MSA Tipo II) Analizar: Intente encontrar las causas fundamentales del problema utilizando varios métodos estadísticos, como histogramas, regresión, correlación, identificación de distribución, análisis de varianza y gráficos multivariados. Mejorar: Utiliza experimentos diseñados, es decir, factoriales completos y fraccionarios, diseños de superficies de respuesta, diseños de mezclas, diseños de taguchi y el concepto de deseabilidad para encontrar configuraciones o soluciones óptimas para un problema. Controlar: Una vez que se logró una mejora, es necesario asegurarla, lo que significa que se deben implementar acuerdos para garantizar el nivel de mejora. El uso de control estadístico de procesos (es decir, gráficos de control de calidad) se puede utilizar para monitorear el comportamiento de un proceso 5.1 Fase 1: Definir La mayoría de las técnicas utilizadas en esta fase no están relacionadas con el uso sustancial de métodos estadísticos. Su objetivo es captar los conocimientos e ideas sobre el proceso involucrado, establecer un objetivo común y definir cómo cada parte contribuye a la solución. Una técnica de visualización clásica que se utiliza en esta fase y está disponible en el paquete QualityTools es el Diagrama de Pareto, que nos ayuda a separar las pocas causas vitales de las muchas causas triviales. Por ejemplo, en la causa más frecuente de un producto defectuoso, el diagrama de Pareto nos ayuda a visualizar cuánto contribuye una causa a un problema. Supongamos que una empresa está investigando unidades (productos) que no cumplen. 120 unidades fueron investigadas y se encontraron 6 tipos diferentes de defectos (datos cualitativos). Los defectos son denominados de A a F por fines prácticos. defectos = c(rep(&quot;E&quot;,62),rep(&quot;B&quot;,15),rep(&quot;F&quot;,3),rep(&quot;A&quot;,10),rep(&quot;C&quot;,20),rep(&quot;D&quot;,10)) paretoChart(defectos) En este diagrama de Pareto podría transmitir el mensaje de que para resolver el \\(68\\%\\) de los problemas, el \\(33 \\%\\) de las causas (menos vitales) necesitan ser objeto de investigación. Además de este uso, los diagramas de Pareto también se utilizan para visualizar los tamaños de efectos de los diferentes factores para los experimentos diseñados, a continución se muestra un ejemplo de una gráfica de errores de medición. 5.2 Fase 2: Medir La recopilación de datos implica el uso de sistemas de medición a menudo denominados calibres. Para hacer una declaración sobre la calidad, el sistema de medición utilizado debe ser validado, y por lo tanto la variación para repetidas mediciones de la misma unidad debe ser tolerable, y por supuesto, debe depender del número de categorías distintivas qque necesita para poder identificar y caracterizar el producto. Esta cantidad tolerable de variación para un sistema de medición se relaciona directamente al rango de tolerancia de las características de un producto. La capacidad de un sistema de mediciones es crucial para cualquier conclusión basada en datos y está directamente relacionada con los costos que implican los errores tipo I y tipo II. 5.2.1 Capacidad de calibre - MSA Tipo I Supongamos que un ingeniero quiere comprobar la capacidad de un dispositivo de medición óptico. Una unidad con característica conocida (\\(x_m = 10.033mm\\)) se mide repetidamente \\(n=25\\) veces. De los valores de medición se obtiene la media \\(\\bar{x_g}\\) y la desviación estándar \\(s_g\\). Basicamente el cálculo de un índice de capacidad comprende dos pasos: primero se calcula una fracción del ancho de toletancia (es decir, \\(USL - LSL\\)), la fracción típicamente se relaciona a \\(0.2\\). En un segundo paso esta fracción se relaciona con una medida de la dispersión del proceso (es decir, el rango en el que el \\(95,5\\%\\), o el \\(99.73\\%\\) de las características de un proceso son esperados). Para valores de medición distribuidos normalmentem esto se relaciona con \\(k = 2 \\sigma_g\\) y \\(k = 3 \\sigma_g\\) calculados a partir de llos valores de medición; y para datos que no están distribuidos normalmente, se pueden tomar los cuantiles correspondientes. Si no hay sesgo, este cálculo representa el índice de capacidad \\(c_g\\) y refleja la verdadera capacidad del dispositivo de medición. \\[ \\begin{aligned} c_g &amp;= \\frac{0.2 \\cdot (USL - LSL)}{6 \\cdot s_g} \\\\ &amp;= \\frac{0.2 \\cdot (USL - LSL)}{X_{0.99865} - X_{0.00135}} \\end{aligned} \\] Sin embargo, si hay un sesgom se tiene en cuenta al restarlo del numerador, en este caso, \\(c_g\\) refleja solo la capacidad potencial (es decir, la capacidad si se corrige el sesgo), y \\(c_{gk}\\) es un estimador de la capacidad real. El sesgo se calcula como la diferencia entre la característica conocida \\(x_m\\) y la media de los valoes de medición \\(x_g\\). \\[ c_{gk} = \\frac{0.1 \\cdot (USL - LSL) - |x_m - x_g|}{3 \\cdot s_g} \\] Determinar si el sesgo se debe al azar o no, se puede hacer con la ayuda de una prueba t que tiene la forma general siguiente: \\[ t = \\frac{diferencia de medias}{error estandar de la diferencia} = \\frac{Dif}{s_{Dif}/\\sqrt{n}} \\] Además del sesgo y la desviación estándar, es importante comprobar el diagrama de ejecución de los valores de medición. Usando el paquete QualityTools, todo esto se logra fácilmente usando el método cg, su resultado se muestra a continuación: library(qualityTools) x &lt;- c ( 9.991, 10.013, 10.001, 10.007, 10.010, 10.013, 10.008, 10.017, 10.005, 10.005, 10.002, 10.017, 10.005, 10.002, 9.996, 10.011, 10.009 , 10.006, 10.008, 10.003, 10.002, 10.006, 10.010, 9.992, 10.013) cg(x, target = 10.003, tolerance = c(9.903, 10.103)) 5.2.2 Repetibilidad y reproducibidad del calibre - MSA Tipo II Un procedimineto común aplicado en la industria es realizar un análisis Gage R&amp;R para evaluar la repetibilidad y reproducibilidad de un sistema de medición (‘R&amp;R’ significa repetibilidad y reproducibilidad). La repetibilidad se refiere a la precisión de un sistema de medición, es decir, a la desviación estándar de mediciones posteriores de la misma unidad. miestras que reproducibilidad es la parte de la varianza general que modela el efecto de diferentes, por ejemplo, operadores que realizan mediciones en la misma unidad y una posible interacción entre diferentes operadores y piezas medidas dentro de este “Gage R&amp;R”, el modelo general está dado por: \\[ \\sigma^2_{total} = \\sigma^2_{Piezas} + \\sigma^2_{Operadores} + \\sigma^2_{Piezas \\times Operador} + \\sigma^2_{Error} \\] Donde: \\(\\sigma^2_{Piezas}\\): modela la variación entre diferentes unidades de un mismo proceso, por lo tanto, \\(\\sigma\\) es una estimación de la variabilidad inherente del proceso. $^2_{Operador} + ^2_{Piezas Operador} $: modela la reproducibilidad. \\(\\sigma^2_{Error}\\): modela la repetibilidad. Ahora, supongamos que 3 operadores elegidos al azar midieron 10 unidades elegidas al azar. Cada operador midió cada unidad dos veces en un orden elegido al azar y las unidades no puedes distingirse entre si. El Diseño R&amp;R del Calibre correspondiente se puede crear utilizando el método gageRRDesign del paquete QualityTools, y las medidas se asignan a este diseño utilizando el método de respuesta, dados por gageRR y plot. library(qualityTools) # Crear un diseño R&amp;R de Calibre dis &lt;- gageRRDesign(Operators = 3, Parts = 10, Measurements = 2, randomize = FALSE) # Establecemos las respuestas de medición response(dis) &lt;- c(23, 22, 22, 22, 22, 25, 23, 22, 23, 22, 20, 22, 22, 22, 24, 25, 27, 28, 23, 24, 23, 24, 24, 22, 22, 22, 24, 23, 22, 24, 20, 20, 25, 24, 22, 24, 21, 20, 21, 22, 21, 22, 21, 21, 24, 27, 25, 27, 23, 22, 25, 23, 23, 22, 22, 23, 25, 21, 24, 23) # Realizamos Gage R&amp;R gdo &lt;- gageRR_abc(dis) ## ## AnOVa Table - crossed Design ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Operator 2 20.63 10.317 8.597 0.00112 ** ## Part 9 107.07 11.896 9.914 7.31e-07 *** ## Operator:Part 18 22.03 1.224 1.020 0.46732 ## Residuals 30 36.00 1.200 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ---------- ## AnOVa Table Without Interaction - crossed Design ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Operator 2 20.63 10.317 8.533 0.000675 *** ## Part 9 107.07 11.896 9.840 2.39e-08 *** ## Residuals 48 58.03 1.209 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ---------- ## ## Gage R&amp;R ## VarComp VarCompContrib Stdev StudyVar StudyVarContrib ## totalRR 1.664 0.483 1.290 7.74 0.695 ## repeatability 1.209 0.351 1.100 6.60 0.592 ## reproducibility 0.455 0.132 0.675 4.05 0.364 ## Operator 0.455 0.132 0.675 4.05 0.364 ## Operator:Part 0.000 0.000 0.000 0.00 0.000 ## Part to Part 1.781 0.517 1.335 8.01 0.719 ## totalVar 3.446 1.000 1.856 11.14 1.000 ## ## --- ## * Contrib equals Contribution in % ## **Number of Distinct Categories (truncated signal-to-noise-ratio) = 1 # Visualización de Gage R&amp;R plot(gdo) El diagrama de barras ofrece una representación visual de los componentes de la varianza. totalRR representa la repetibilidad y reproducibilidad totales. El \\(48\\%\\) de la variación se debe al \\(35\\%\\) de repitibilidad, es decir, variación del propio calibre, y al \\(13\\%\\) de reproducibilidad, es decir, efecto del operador y la interación entre el operador y la pieza. Se puede ver en la tabla Anova que no existe interacción entre piezas y operadores. El \\(52\\%\\) de la variación (columna VarCompContrib) se debe a diferencias entre las partes tomadas del proceso (variación inherente), que se puede ver en el gráfico Measurement by Part. La variación de las mediciones tomadas por un operador es aproximadamente igual para los tres operadores (Measurement by Operator), aunque el operador C parece producir valores que la mayoría de las veces son mayores que los valores de los otros operadores (Interaction Operator: Part). Además de esta interpretación de los resultados, en la industria se utilizan valores críticos para totalRR, también denominado en la industria como “GRR”. Sin embargo, un sistema de medición nunca debe juzgarse únicamente por sus valores críticos. Contribución total RR Capacidad ≤ 0.1 Adecuada &lt; 0.1 y &lt; 0.3 Adecuada con limitaciones dependiendo de las circunstancias ≥ 0.3 No adecuada Verificación de interacción: El gráfico de interacción proporciona una verificación visual de posibles interacciones entre el Operador y la Pieza. Para cada operador se muestra el valor medio de la medición en función del número de pieza. Las líneas cruzadas indican que los operadores están asignando lecturas diferentes a idénticas dependiendo de la combinación de Operador y Pieza. Diferentes lecturas significan, en el caso de una interacción entre Operador y Pieza, que en promedio a veces se asignan valores más pequeños o más grandes dependiendo de la combinación de Operador y Pieza. En este caso, las líneas prácticamente no se cruzan, pero el operador C parece asignar sistemáticamente lecturas mayores a las piezas que sus colegas. Operadores: Para comprobar si hay un efecto dependiente del operador, las mediciones se trazan agrupadas por operadores en forma de diagramas de caja. Los diagramas de caja que difieren en tamaño o ubicación pueden indicar, por ejemplo, posibles procedimientos diferentes dentro del proceso de medición, que luego conducen a una diferencia sistemática en las lecturas. En nuestro ejemplo se podría discutir un posible efecto para el operador C que también está respaldado por el gráfico de interacción. Variación inherente del proceso: Dentro de este gráfico las mediciones están agrupadas por operador. Gracias a las mediciones repetidas realizadas por diferentes operadores por pieza, se obtiene una idea del proceso. Una línea que conecta la media de las mediciones de cada parte proporciona una idea de la variación inherente del proceso. Cada pieza se mide el número de operadores multiplicado por el número de mediciones por pieza. Componentes de Variación: Para comprender el resultado de un estudio de Gage R&amp;R se debe hacer referencia a la fórmula presentada al inicio de esta sección. El componente de varianza totalRR (columna VarComp) representa la repetibilidad y reproducibilidad total. Dado que las varianzas simplemente se suman, se tiene que \\(1.664\\) es la suma de \\(1.209\\) (repetibilidad dada por \\(\\sigma^2_{Error}\\)) y \\(0.455\\) (reproducibilidad) que es la suma de Operador (\\(\\sigma^2_{Operador}\\)) y Operador:Parte (\\(\\sigma^2_{Partes \\times Operador}\\)). Como no hay interacción, la reproducibilidad asciende a \\(0.455\\). Parte a Parte asciende a \\(1.781\\). Junto con el total de repetibilidad y reproducibilidad, esto da \\(\\sigma^2_{Total} = 3.446\\). 5.3 Fase 3: Analizar 5.3.1 Capacidad del Proceso Además de la capacidad de un sistema de medición, a menudo la capacidad de un proceso es de interés o necesidad que debe evaluarse, por ejemplo, como parte de una relación entre proveedor y cliente en la industria. Los índices de capacidad del proceso básicamente indican cuánto del rango de tolerancia está siendo utilizado por la variación debida a causas comunes del proceso considerado. Utilizando estas técnicas, se puede determinar cuántas unidades (por ejemplo, productos) se espera que caigan fuera del rango de tolerancia, es decir, defectuoso con respecto a los requisitos determinados. También proporciona información sobre dónde centrar el proceso si el desplazamiento es posible y significativo en términos de costos. \\[ c_p = \\frac{USL - LSL}{Q_{0.99865} - Q_{0.00135}} \\] \\[ c_{pkL} = \\frac{Q_{0.5} - LSL}{Q_{0.5} - Q_{0.00135}} \\] \\[ c_{pkU} = \\frac{USL - Q_{0.5}}{Q_{0.99865} - Q_{0.5}} \\] * \\(c_p\\): Es la capacidad potencial del proceso que podría lograrse si el proceso se pudiera centrar dentro de los límites de especificación. \\(c_{pk}\\): Es la capacidad real del proceso que incorpora la ubicación de la distribución (es decir, el centro) de la característica dentro de los límites de especificación. Para límites de especificación unilaterales, existen \\(c_{pkL}\\) y \\(c_{pkU}\\), siendo \\(c_{pk}\\) igual al índice de capacidad más pequeño. Como se puede imaginar, además de la ubicación de la distribución de la característica, la forma de la distribución también es relevante. Evaluar el ajuste de una distribución específica para datos dados se puede hacer a través de gráficos de probabilidad (ppPlot) y gráficos de cuantiles-cuantiles (qqPlot), así como métodos de prueba formales como la Prueba de Anderson-Darling. Las capacidades del proceso pueden calcularse con el método pcr del paquete qualityTools. El método pcr traza un histograma de los datos, la distribución ajustada y devuelve los índices de capacidad junto con los parámetros estimados de la distribución, una Prueba de Anderson-Darling para la distribución especificada y el correspondiente QQ-Plot. Ejemplos: Distribución Normal set.seed(1234) datos &lt;- rnorm(20, mean = 20) pcr(datos, &quot;normal&quot;, lsl = 17, usl = 23) ## Error in round(x$statistic, 4): non-numeric argument to mathematical function Distribución Weibull set.seed(1234) weib &lt;- rweibull(20, shape = 2, scale = 8) pcr(weib, &quot;weibull&quot;, usl = 20) ## Error in round(x$statistic, 4): non-numeric argument to mathematical function Junto con la representación gráfica se presenta un Test de Anderson Darling y se devuelve la distribución Los gráficos QQ-plot pueden obtenerse a partir del paquete QualityTools, de la siguiente forma: par(mfrow = c(1,2)) qqPlot(weib, &quot;weibull&quot;); qqPlot(datos, &quot;normal&quot;) Y los gráficos de probabilidad se pueden calcular con la función ppPlot del mismo paquete, de la siguiente manera: par(mfrow = c(1,2)) ppPlot(weib, &quot;weibull&quot;); ppPlot(datos, &quot;normal&quot;) 5.4 Fase 4: Mejorar 5.4.1 Diseños factoriales \\(2^{k}\\) El método facDesign diseña un modelo de k factores y 2 combinaciones por factor, el cual es llamado \\(2^k\\). Supondremos un ejemplo de un proceso que tiene 5 factores A, B, C, D y E, de los cuales tres se consideran relevantes para el rendimiento del proceso (A, B y C). set.seed(1234) dfac &lt;- facDesign(k = 3, centerCube = 4) names(dfac) &lt;- c(&#39;Facto 1&#39;, &#39;Factor 2&#39;, &#39;Factor 3&#39;) lows(df) &lt;- c(80,120,1) highs(fdo) &lt;- c(120,140,2) summary(dfac) El proceso se simula con el método simProc: #Primeros valores rend &lt;- simProc(x1=120,x2=140,x3=2) #valores completos rend = c(simProc(120,140,1),simProc(80,140,1),simProc(120,140,2),simProc(120,120,1),simProc(90,130,1.5),simProc(90,130,1.5),simProc(80,120,2),simProc(90,130,1.5),simProc(90,130,1.5),simProc(120,120,2),simProc(80,140,2),simProc(80,120,1)) Se asigna el rendimiento al diseño factorial: response(dfac) &lt;- rend Para el análisis del diseño se puede usar los métodos effectPlot, interactionPlot, lm, wirePlot, contourPlot. effectPlot(dfac, classic = TRUE) interactionPlot(dfac) Se puede usar el método de R lm, vemos a continuación: m1 &lt;- lm(rend ~ A*B*C, data=dfac) summary(m1) Se puede que ver que A, B y AB son significativos. También se puede obtener dos gráficas mediante paretoPlot y normalPlot del mismo paquete qualityTools. par(mfrow=c(1,2)) paretoPlot(dfac) normalPlot(dfac) La relación entre el factor A y el B se puede visualizar mediante una representación 3D mediante wirePlot y contourPlot par(mfrow=c(1,2)) wirePlot(A,B,rend,data=dfac) contourPlot(A,B,rend,data=dfac) 5.4.2 Diseños factoriales fraccionarios \\(2^{k-p}\\) Este diseño tiene \\(k\\) factores y se prueba en \\(2k-p\\) ejecuciones, por ejemplo para un diseño \\(2^{5-1}\\) se prueban cinco factores en 24 ejecuciones. Para realizar esto se utiliza el método fracDesign, vamos a realizar el ejemplo de un diseño \\(2^{3-1}\\), para ello se debe utilizar el argumento gen='C=AB', lo cual quiere decir que el efecto de C es equivalente al de AB: dfacfrac &lt;- fracDesign(k=3,gen=&#39;C=AB&#39;,centerCube = 4) Se puede obtener información específica del diseño mediante summary: summary(dfacfrac) Vemos que en el modelo se muestra que I=ABC y por lo tanto se cumplen las siguientes reglas: \\[\\begin{align} I\\times A&amp;=A\\\\ A\\times A&amp;=I\\\\ A\\times B&amp;=B\\times A \\end{align}\\] Para encontrar todos los efectos equivalentes se puede usar los comandos: aliasTable(dfacfrac) confounds(dfacfrac) Estos diseños se pueden generar asignando los generadores apropiados, el cual se puede elegir entre tabla predefinidas usando el método fracChoose y seleccionando el diseño deseado: fracChoose() 5.4.3 Diseños replicados y puntos centrales Se puede crear un diseño replicado con puntos centrales adicionales usando replicates y centerCube: dfac1 &lt;- facDesign(k = 3, centerCube = 2, replicates = 2) 5.4.4 Respuestas múltiples Se puede agregar vectores de respuesta al diseño con el método response. Por ejemplo, se crea una segunda respuesta y2 que se llena con números aleatorios y se agrega al objeto creado. set.seed(1234) y2 &lt;- rnorm(12,mean=120) response(dfac) &lt;- data.frame(yield,y2) Se puede visualizar en 3D con los métodos wirePlot y contourPlot especificando con form: par(mforw = c(1,2)) wirePlot(A, B, yield, data = dfac, form = &quot;yield~A+B+C+A*B&quot;) contourPlot(A, B, y2, data = fdo, form = &quot;y2~A+B+C+A*B&quot;) Se puede crear los gráficos con el tercer factor C en -1 y \\(C=1\\), de la forma: par(mfrow = c(1,2)) wirePlot(A, B, y2, data = dfrac, factors = list(C=-1), form = &quot;y2~A*B*C&quot;) wirePlot(A, B, y2, data = dfrac, factors = list(C=1), form = &quot;y2∼A∗B∗C&quot;) Si no se proporciona ninguna fórmula explícitamente, los métodos predeterminados son el ajuste completo o el que está almacenado en el objeto de diseño factorial. El almacenamiento del ajusto se puede realizar con el método fits y se utiliza cuando se trabaja con más de una respuesta. Además, se utiliza lm para analizar el diseño factorial fraccionario. fits(fdo) &lt;- lm(yield∼A+B, data = fdo) fits(fdo) &lt;- lm(y2∼A∗B∗C, data = fdo) fits(fdo) 5.4.5 Pasar a un entorno de proceso con un mayor rendimiento esperado Como el proceso puede ser modelado por una relación lineal se puede determinar un alto rendimiento fácilmente, esto se puede calcular gráficamente o utilizando el método steepAscent: sao &lt;- steepAscent(factors = c(&quot;A&quot;, &quot;B&quot;), response = &quot;yield&quot;, data = dfac, steps = 20) sao Como se estableció los valores reales anteriormente con los métodos highs y lows son mostrados como valores reales. Los valores de respuesta de sao pueden ser establecidos con el método response y graficados con plot predicted &lt;- simProc(sao[,5], sao[,6]) responde(sao) &lt;- predicted plot(sao, type=&#39;b&#39;, col=2) 5.4.6 Diseños de superficies de respuesta Se debe tener en cuenta que no todas las relaciones son lineales por lo cual para detectar y modelizar las relaciones no lineales se necesitan más de dos combinaciones por factor. Para averiguar si un diseño de superficie de respuesta es necesario (es decir, un diseño con más de dos combinaciones por factor) se puede comparar el valor esperado de la(s) variable(s) de respuesta con la(s) observada(s) utilizando puntos centrales . Cuanto mayor sea la diferencia entre los valores esperados, más improbable será que esta diferencia sea el resultado de ruido aleatorio. Bajo el contexto del ejercicio desarrollado en la sección de diseño factorial \\(2^{k}\\) utilizamos el método steepAscent de qualityTools para pasar a una mejor región del proceso. El centro de la nueva región de proceso está definido por 144 y 165 en valores reales la cual es el inicio del nuevo diseño. #Semilla set.seed(1234) fdo2 &lt;- facDesign(k = 2, centerCube = 3) names(fdo2) &lt;- c(&quot;Factor1&quot;, &quot;Factor2&quot;) lows(fdo2) &lt;- c(13, 4, 155) highs(fdo2) &lt;- c(15, 5, 175) el rendimiento se obtiene utilizando el simProc y se asigna al nuevo diseño con la ayuda del método genérico de response del paquete qualityTools rendimiento=c(simProc(134,175),simProc(144.5,165.5),simProc(155,155),simProc(144.5,165.5),simProc(155,175),simProc(144.5,165.5),simProc(134,155)) response(fdo2)=rendimiento Si se observan los gráficos de residuos, se apreciará una diferencia sustancial entre los valores esperados y los valores observados (podría realizarse una prueba de falta de ajuste para verificarlo). Para llegar a un modelo que describa la relación hay que añadir más puntos que se denominan la starportion del diseño de la superficie de respuesta. La adición de la starportion se realiza fácilmente utilizando el método starDesign del paquete qualityTools Por defecto, el valor de alfa se elige de forma que ambos criterios, ortogonalidad y rotatabilidad se cumplan . Se llama al método starDesign en el objeto de diseño factorial factorial fdo2. La llamada a rsdo le mostrará el diseño de superficie de respuesta resultante.Debe tener una porción cúbica que conste de 4 runs, 3 puntos centrales en la porción cúbica, 4 axiales y 3 puntos centrales en la porción de estrella (starportion). rsdo= starDesign( data =fdo2 ) rsdo StandOrd RunOrder Block A B rendimiento 3 3 1 1 -1.000 3769 7 7 2 1 0.000 7953 2 2 3 1 -1.000 7935 6 6 4 1 0.000 7865 4 4 5 1 1.000 NA 5 5 6 1 0.000 NA 1 1 7 1 -1.000 NA 8 8 8 2 -1.414 NA 9 9 9 2 1.000 NA 10 10 10 2 0.000 NA 11 11 11 2 0.000 NA 12 12 12 2 0.000 NA 13 13 13 2 0.000 NA 14 14 14 2 0.000 NA Utilizando el método estrella del paquete qualityTools se pueden ensamblar fácilmente diseños secuencialmente. Esta estrategia secuencial ahorra recursos pues, en comparación con empezar con diseño de superficie de respuesta desde el principio, la parte en estrella sólo se ejecuta si es realmente necesaria. Los rendimientos del proceso siguen estando dados por el método simProc. yield2 &lt;- c( yield, simProc(130, 165), simProc(155, 165), simProc(144, 155), simProc(144, 179), simProc(144, 165), simProc(144, 165), simProc(144, 165) ) response(rsdo) &lt;- yield2 Se ajusta un modelo cuadrático completo utilizando el método lm lm.3 &lt;- lm(yield2 ~ A*B + I(A^2) + I(B^2), data = rsdo) La superficie de respuesta puede visualizarse utilizando wirePlot y contourPlot. par(mfrow = c(1, 2)) wirePlot(A, B, yield2, form = &quot;yield2 ~ A*B + I(A^2) + I(B^2)&quot;, data = rsdo, theta = -70) contourPlot(A, B, yield2, form = &quot;yield2 ~ A*B + I(A^2) + I(B^2)&quot;, data = rsdo) Se compara los resultados de los diseños factorial y de superficie de respuesta con el proceso simulado. Se pueden crear diseños de superficie de respuesta utilizando el método rsmDesign. Por ejemplo un diseño con alfa = 1.633, 0 puntos centrales en la parte del cubo y 6 puntos centrales en la parte de la estrella con: fdo &lt;- rsmDesign(k = 3, alpha = 1.633, cc = 0, cs = 6) y el diseño se puede poner en orden estándar utilizando el método randomize con el argumento so=TRUE (es decir, orden estándar). cc significa centerCube y cs para centerStar. fdo &lt;- randomizeDesign(fdo, so = TRUE) Los diseños de superficie de respuesta también pueden elegirse a partir de una tabla utilizando el método rsmChoose. rsdo &lt;- rsmDesign() &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ### Montaje secuencial de diseños de superficie de respuesta ======= #### Montaje secuencial de diseños de superficie de respuesta &gt;&gt;&gt;&gt;&gt;&gt;&gt; 38aa7fcbe69006ca620167942eac17f3b64293c9 El ensamblaje secuencial es una característica importante de los diseños de superficie de respuesta. En función de de las características del diseño factorial (fraccional) puede aumentarse una porción de estrella utilizando el método starDesign. Una porción en estrella consta de recorridos axiales y puntos centrales opcionales (cs) en la parte axial a diferencia de los puntos centrales (cc) en la parteparte cúbica. fdo3 &lt;- facDesign(k = 6) rsdo &lt;- starDesign(alpha = &quot;orthogonal&quot;, data = fdo3) En caso de que no se entregue ningún diseño factorial (fraccional) al método starDesign, se devuelve una lista con data.frames que pueden asignarse al diseño factorial (fraccional) existente utilizando los métodos star, centerStar y centerCube. &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ### Aleatorización ======= #### Aleatorización &gt;&gt;&gt;&gt;&gt;&gt;&gt; 38aa7fcbe69006ca620167942eac17f3b64293c9 La aleatorización se consigue utilizando el método randomize. Es necesario suministrar una semilla aleatoria (random.seed) que es útil para tener el mismo orden de ejecución en cualquier máquina. randomize(fdo, random.seed = 123) El método randomize se puede utilizar para obtener un diseño en orden estándar con la ayuda del argumento so. randomizeDesign(fdo, so = TRUE) &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ### Bloqueo ======= #### Bloqueo &gt;&gt;&gt;&gt;&gt;&gt;&gt; 38aa7fcbe69006ca620167942eac17f3b64293c9 El bloqueo es otra característica relevante y puede conseguirse mediante el método de blocking. Bloquear un diseño a posteriori no siempre tiene éxito. Sin embargo, no es problemático durante el montaje secuencial. 5.5 Deseabilidades Muchos problemas requieren optimización simultánea de más de una variable de respuesta. La optimización puede lograrse maximizando o minimizando el valor de la respuesta o tratando de situar la respuesta en un objetivo específico.En la Optimización mediante el enfoque de las deseabilidades Derringer y Suich [1980], los valores (predichos) de las variables de respuesta se transforman en valores dentro del intervalo [0,1] utilizando tres métodos de deseabilidad diferentes para los tres criterios de optimización diferentes (es decir, minimizar, maximizar, objetivo). A cada valor de una variable de respuesta se le puede asignar una deseabilidad específica, optimizando más de una variable de respuesta. La media geométrica de las deseabilidades específicas caracteriza la deseabilidad global. \\[\\sqrt[n]{\\prod^n_{i=1}d_i}\\] Para los valores previstos de las respuestas, cada combinación de factores tiene una correspondiente deseabilidad específica y se puede calcular una deseabilidad global. Supongamos que tenemos tres respuestas. Para un ajuste específico de los factores, las respuestas tienen deseabilidades como \\(d1 = 0,7\\) para \\(y1, d2 = 0,8\\) para \\(y2\\) y \\(d3 = 0,2\\) para \\(y3\\). La deseabilidad global viene dada por la media geométrica. \\[d_{all}=\\sqrt[n]{d_1d_2\\ldots d_n}\\] \\[=\\sqrt[3]{d_1d_2\\ldots d_n}\\] \\[=\\sqrt[n]{0.7\\cdot0.8\\cdot0.2}\\] Los métodos de deseabilidad pueden definirse mediante el método desires. La dirección de optimización de cada variable de respuesta se define mediante los argumentos min,max y target del método desires. El argumento target se establece con max para la maximización, min para la minimización y un valor específico para la optimización hacia un objetivo concreto. De esta constelación surgen tres ajustes: target = max: min es el valor mínimo aceptable. Si la variable de respuesta toma valores por debajo de min, la deseabilidad correspondiente será cero. Para valores iguales o mayores que min, la deseabilidad será mayor que cero. target = min: max es el valor máximo aceptable. Si la variable de respuesta toma valores por encima de max, la deseabilidad correspondiente será cero. Para valores iguales o menores que max, la deseabilidad será mayor que cero. target = valor: una variable de respuesta con un valor de valor se relaciona con la deseabilidad más alta alcanzable de 1. Los valores fuera de min o max llevan a una deseabilidad de cero, dentro de min y max a valores dentro de (0,1]. #EJEMPLO: d1 &lt;- desirability(y1, 120, 170, scale = c(1, 1), target = &quot;max&quot;) d3 &lt;- desirability(y3, 400, 600, target = 500) d1 par(mfrow = c(1, 2)) plot(d1, col = 2) plot(d3, col = 2) 5.6 Utilización de deseabilidades junto con experimentos diseñados La metodología de la deseabilidad se apoya en los objetos de diseño factorial. El resultado del método de deseabilidad puede almacenarse en el objeto de diseño, de modo que la información que pertenece a cada uno se almacena en el mismo lugar (es decir, el propio diseño). Experimento Los datos utilizados proceden de Derringer y Suich [1980]. Se definieron cuatro respuestas \\(y_1, y_2, y_3\\) e \\(y_4\\). Los factores utilizados en este experimento fueron la sílicio, el silano y el azufre con ajustes de factor alto de \\(1,7, 60, 2,8\\) y factores bajos de \\(0,7, 40, 1,8\\). Se desea maximizar \\(y_1\\) e \\(y_2\\) e \\(y_3\\) e \\(y_4\\) fijados en un objetivo específico. En primer lugar, se crea el diseño correspondiente y a continuación, utilizamos el método randomize para obtener el orden estándar del diseño. ddo &lt;- rsmDesign(k = 3, alpha = 1.633, cc = 0, cs = 6) ddo &lt;- randomize(ddo, so = TRUE) # Opcional names(ddo) &lt;- c(&quot;silica&quot;, &quot;silan&quot;, &quot;sulfur&quot;) # Opcional highs(ddo) &lt;- c(1.7, 60, 2.8) # Opcional lows(ddo) &lt;- c(0.7, 40, 1.8) # y1 &lt;- c(102, 120, 117, 198, 103, 132, 132, 139, 102, 154, 96, 163, 116, 153, 133, 133, 140, 142, 145, 142) y2 &lt;- c(900, 860, 800, 2294, 490, 1289, 1270, 1090, 770, 1690, 700, 1540, 2184, 1784, 1300, 1300, 1145, 1090, 1260, 1344) y3 &lt;- c(470, 410, 570, 240, 640, 270, 410, 380, 590, 260, 520, 380, 520, 290, 380, 380, 430, 430, 390, 390) y4 &lt;- c(67.5, 65, 77.5, 74.5, 62.5, 67, 78, 70, 76, 70, 63, 75, 65, 71, 70, 68.5, 68, 68, 69, 70) El data.frame ordenado de estas 4 respuestas se asigna al objeto de diseño ddo. response(ddo) &lt;- data.frame(y1, y2, y3, y4)[c(5, 2, 3, 8, 1, 6, 7, 4, 9:20), ] Las deseabilidades se incorporan con el método desires . Ya se han definido \\(y_1\\) e \\(y_3\\), por lo que quedan por definir las deseabilidades de \\(y_2\\) e \\(y_4\\). d2 &lt;- desirability(y2, 1000, 1300, target = &quot;max&quot;) d4 &lt;- desirability(y4, 60, 75, target = 67.5) Es necesario definir las deseabilidades con los nombres de las variables de respuesta para poder utilizarlas con el objeto de diseño. El método de los deseos se utiliza del siguiente modo desires(ddo) &lt;- d1 desires(ddo) &lt;- d2 desires(ddo) &lt;- d3 desires(ddo) &lt;- d4 Los ajustes se establecen como en Derringer y Suich [1980] utilizando los métodos de ajuste del paquete qualityTools de calidad. fits(ddo) &lt;- lm(y1 ~ A + B + C + A:B + A:C + B:C + I(A^2) + I(B^2) + I(C^2), data = ddo) fits(ddo) &lt;- lm(y2 ~ A + B + C + A:B + A:C + B:C + I(A^2) + I(B^2) + I(C^2), data = ddo) fits(ddo) &lt;- lm(y3 ~ A + B + C + A:B + A:C + B:C + I(A^2) + I(B^2) + I(C^2), data = ddo) fits(ddo) &lt;- lm(y4 ~ A + B + C + A:B + A:C + B:C + I(A^2) + I(B^2) + I(C^2), data = ddo) Finalmente se tiene que optimum(ddo, type = &quot;optim&quot;) ## Diseños de mezclas La generación de los diferentes tipos de diseños de mezcla es totalmente compatible incluyendo un contorno ternario y un gráfico 3D. El análisis de estos diseños debe realizarse sin ningún soporte específico mediante un método del paquete qualityTools. El método mixDesign puede utilizarse, por ejemplo, para crear diseños de celosía simplex y diseños de centroide simplex. Los métodos genéricos response, names, highs, lows, units y types vuelven a estar presentes. Un conjunto de datos Cornell [op. 2002] viene dado por el alargamiento del hilo para varias mezclas de tres factores. Este ejemplo puede reconstruirse utilizando el método mixDesign. #EJEMPLO mdo &lt;- mixDesign(3, 2, center = FALSE, axial = FALSE, randomize = FALSE, replicates = c(1, 1, 2, 3)) ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list embedding ## of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list embedding ## of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list embedding ## of S4 objects is deprecated names(mdo) &lt;- c(&quot;polyethylene&quot;, &quot;polystyrene&quot;, &quot;polypropylene&quot;) # Establecer respuesta (es decir, elongación del hilo) elongation &lt;- c(11.0, 12.4, 15.0, 14.8, 16.1, 17.7, 16.4, 16.6, 8.8, 10.0, 10.0, 9.7, 11.8, 16.8, 16.0) response(mdo) &lt;- elongation ## [1] &quot;elongation&quot; mdo ## StandOrder RunOrder Type A B C elongation ## 1 1 1 1-blend 1.0 0.0 0.0 11.0 ## 2 2 2 1-blend 1.0 0.0 0.0 12.4 ## 3 3 3 2-blend 0.5 0.5 0.0 15.0 ## 4 4 4 2-blend 0.5 0.5 0.0 14.8 ## 5 5 5 2-blend 0.5 0.5 0.0 16.1 ## 6 6 6 2-blend 0.5 0.0 0.5 17.7 ## 7 7 7 2-blend 0.5 0.0 0.5 16.4 ## 8 8 8 2-blend 0.5 0.0 0.5 16.6 ## 9 9 9 1-blend 0.0 1.0 0.0 8.8 ## 10 10 10 1-blend 0.0 1.0 0.0 10.0 ## 11 11 11 2-blend 0.0 0.5 0.5 10.0 ## 12 12 12 2-blend 0.0 0.5 0.5 9.7 ## 13 13 13 2-blend 0.0 0.5 0.5 11.8 ## 14 14 14 1-blend 0.0 0.0 1.0 16.8 ## 15 15 15 1-blend 0.0 0.0 1.0 16.0 par(mfrow = c(1, 2)) contourPlot3(A, B, C, elongation, data = mdo, form = &quot;quadratic&quot;) wirePlot3(A, B, C, elongation, data = mdo, form = &quot;quadratic&quot;, theta = -170) 5.7 Diseños Taguchi Los diseños Taguchi están disponibles utilizando el método taguchiDesign. Hay dos tipos de diseños taguchi: Nivel único: todos los factores tienen el mismo número de niveles (por ejemplo, dos niveles para un L4_2). Nivel mixto: los factores tienen diferentes números de niveles (por ejemplo, dos y tres niveles para un L18_2_3). Sin embargo, la mayoría de los diseños que se popularizaron como diseños Taguchi son factoriales fraccionados \\(2^k\\) con una resolución muy baja de III (es decir, los efectos principales se confunden con interacciones de dos factores) u otros diseños de nivel mixto. Se puede crear un diseño utilizando el método taguchiDesign. Los nombres de métodos genéricos, unidades, valores, resumen, trazado, lm y otros métodos se pueden utilizar. #EJEMPLO set.seed(1234) tdo &lt;- taguchiDesign(&quot;L9_3&quot;) ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;taguchiFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;taguchiFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;taguchiFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;taguchiFactor&quot;)): implicit list ## embedding of S4 objects is deprecated values(tdo) &lt;- list(A = c(20, 40, 60), B = c(&quot;material 1&quot;, &quot;material 2&quot;, &quot;material 3&quot;), C = c(1, 2, 3)) names(tdo) &lt;- c(&quot;Factor 1&quot;, &quot;Factor 2&quot;, &quot;Factor 3&quot;, &quot;Factor 4&quot;) summary(tdo) ## Taguchi SINGLE Design ## Information about the factors: ## ## A B C D ## value 1 20 material 1 1 1 ## value 2 40 material 2 2 2 ## value 3 60 material 3 3 3 ## name Factor 1 Factor 2 Factor 3 Factor 4 ## unit ## type numeric numeric numeric numeric ## ## ----------- ## ## StandOrder RunOrder Replicate A B C D y ## 1 4 1 1 2 1 2 3 NA ## 2 6 2 1 2 3 1 2 NA ## 3 9 3 1 3 3 2 1 NA ## 4 3 4 1 1 3 3 3 NA ## 5 2 5 1 1 2 2 2 NA ## 6 1 6 1 1 1 1 1 NA ## 7 7 7 1 3 1 3 2 NA ## 8 5 8 1 2 2 3 1 NA ## 9 8 9 1 3 2 1 3 NA ## ## ----------- El método response se utiliza para asignar los valores de las variables de respuesta. effectPlot puede utilizarse una vez más para visualizar los tamaños del efecto de los factores response(tdo) &lt;- rnorm(9) effectPlot(tdo, col = 2) Como extra es importante el uso del comando sessionInfo con el fin de obtener el número de versión de R y los paquetes cargados : sessionInfo() ## R version 4.3.1 (2023-06-16 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 11 x64 (build 22631) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=Spanish_Ecuador.utf8 LC_CTYPE=Spanish_Ecuador.utf8 ## [3] LC_MONETARY=Spanish_Ecuador.utf8 LC_NUMERIC=C ## [5] LC_TIME=Spanish_Ecuador.utf8 ## ## time zone: Europe/Paris ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] qualityTools_1.55 MASS_7.3-60 Rsolnp_1.16 ## ## loaded via a namespace (and not attached): ## [1] digest_0.6.33 R6_2.5.1 bookdown_0.38 fastmap_1.1.1 ## [5] xfun_0.40 truncnorm_1.0-9 cachem_1.0.8 parallel_4.3.1 ## [9] knitr_1.45 htmltools_0.5.6 rmarkdown_2.24 cli_3.6.1 ## [13] sass_0.4.7 jquerylib_0.1.4 compiler_4.3.1 highr_0.10 ## [17] rstudioapi_0.15.0 tools_4.3.1 evaluate_0.21 bslib_0.5.1 ## [21] yaml_2.3.7 jsonlite_1.8.7 rlang_1.1.1 "]]
